---

title: 操作系统问题
categories: study
tags : 面试
toc: true

---

# linux
## 基本命令
### grep
grep 命令。强大的文本搜索命令，grep(Global Regular Expression Print) 全局正则表达式搜索。

grep 的工作方式是这样的，它在一个或多个文件中搜索字符串模板。如果模板包括空格，则必须被引用，模板后的所有字符串被看作文件名。搜索的结果被送到标准输出，不影响原文件内容。
```bash
grep -i "http" ./a.log
cat ./a.log |grep "http"
```
-i 忽略大小写

### linux开机自动执行命令如何实现？
- 方法 #1 - 使用 cron 任务

除了常用格式（分 / 时 / 日 / 月 / 周）外，cron 调度器还支持 @reboot 指令。这个指令后面的参数是脚本（启动时要执行的那个脚本）的绝对路径。

然而，这种方法需要注意两点：

a) cron 守护进程必须处于运行状态（通常情况下都会运行），同时

b) 脚本或 crontab 文件必须包含需要的环境变量。

- 方法 #2 - 使用 /etc/rc.d/rc.local

这个方法对于 systemd-based 发行版 Linux 同样有效。不过，使用这个方法，需要授予 /etc/rc.d/rc.local 文件执行权限：
```bash
# chmod +x /etc/rc.d/rc.local
```
然后在这个文件底部添加脚本。

### 查看内存
查看内存使用情况
```bash
free -m
```
-m表示以MB为单位，类似-b Byte -k以KB

top命令

top命令。显示当前系统正在执行的进程的相关信息，包括进程 ID、内存占用率、CPU 占用率等

top是区分不出进程的用户态CPU和内核态CPU


要查看负载情况一般使用 uptime 命令（w 命令和 top 命令也行）

iostat 命令可以查看系统分区的 IO 使用情况

iotop 命令类似于 top 命令，但是显示的是各个进程的 I/O 情况，对于定位 I/O 操作较重的进程有比较大的作用。

使用 sar 命令查看当天 CPU 使用：

uptime可查看过去一分钟、五分钟、十五分钟的平均负载情况

sysstat 工具

很多时候当检测到或者知道历史的高负载状况时，可能需要回放历史监控数据，这时 sar 命令就派上用场了，sar 命令同样来自 sysstat 工具包，可以记录系统的 CPU 负载、I/O 状况和内存使用记录，便于历史数据的回放。

sysstat 的配置文件在 /etc/sysconfig/sysstat 文件，历史日志的存放位置为 /var/log/sa\
统计信息都是每 10 分钟记录一次，每天的 23:59 会分割统计文件，这些操作的频率都在 /etc/cron.d/sysstat 文件配置。


pidstat可查看用户态CPU使用率、内核态CPU使用率、运行虚拟机CPU使用率、等待CPU使用率和总的CPU使用率

vmstat命令可以报告关于进程、内存、I/O等系统整体运行状态


### 查看进程、端口  
>Linux中，如何通过端口查进程，如何通过进程查端口？

linux下通过进程名查看其占用端口： 

（1）先查看进程pid

`ps -ef | grep 进程名`

（2）通过pid查看占用端口

`netstat -nap | grep 进程pid`

linux通过端口查看进程：

`netstat -nap | grep 端口号`
### Tee
`tee`是Linux命令，用于显示程序的输出并将其复制到一个文件中

### $#

- `$#`表示命令行参数个数，而不是上一条命令执行结果的状态码。
- `$*`表示所有命令行参数的字符串，而不是上一条命令执行结果的状态码。
- `$0`表示脚本名字，而不是上一条命令执行结果的状态码。
- `$?`表示上一条命令执行的状态码，如果状态码为 0，表示命令执行成功，否则表示执行失败。因此这个选项是正确的。

## linux内核
### 基本功能
- 内存管理： 追踪记录有多少内存存储了什么以及存储在哪里
- 进程管理： 确定哪些进程可以使用中央处理器（CPU）、何时使用以及持续多长时间
- 设备驱动程序： 充当硬件与进程之间的调解程序/解释程序
- 系统调用和安全防护： 从流程接受服务请求
### 内核态和用户态
从用户态到内核态切换可以通过三种方式：
- 系统调用：系统调用本身就是中断，但是是软件中断，跟硬中断不同。
- 异常：如果当前进程运行在用户态，如果这个时候发生了异常事件，就会触发切换。例如：缺页异常。
- 外设中断：当外设完成用户的请求时，会向CPU发送中断信号

### linux负载
系统负载是对当前CPU工作量的度量，被定义为特定时间间隔内运行队列中的平均线程数。load average 表示机器一段时间内的平均load。这个值越低越好。负载过高会导致机器无法处理其他请求及操作，甚至导致死机。

系统的负载采用的是指数移动平均，计算方法如下：

S(0) = 0 S(t) = a * X(t) + (1-a)*S(t-1)

单核满载是 1，有 n 核满载是 n。一般说线上运行的系统大于 0.7 的时候就要注意了。

## 启动
### 开机自启动
#### Linux如何设置开机启动？


1. 编辑rc.loacl脚本

linux开机之后会执行`/etc/rc.local`文件中的脚本。

所以可以直接在`/etc/rc.local`中添加启动脚本。

`$ vim /etc/rc.local`

2. 添加一个开机启动服务。

将启动脚本复制到 `/etc/init.d`目录下，并设置脚本权限, 假设脚本为test

` $ mv test /etc/init.d/test  $ sudo chmod 755 /etc/init.d/test`

将该脚本放倒启动列表中去

` $ cd .etc/init.d `
` $ sudo update-rc.d test defaults 95`
注：其中数字95是脚本启动的顺序号，按照自己的`需要相应修改即可。在有多个启动脚本，而它们之间又有先后启动的依赖关系时就知道这个数字的具体作用了。

将该脚本从启动列表中剔除

` $ cd /etc/init.d`
` $ sudo update-rc.d -f test remove`

# 协程
>什么是协程？

协程：协程是微线程，在子程序内部执行，可在子程序内部中断，转而执行别的子程序，在适当的时候再返回来接着执行。


>线程与协程的区别：

（1）协程执行效率极高。协程直接操作栈基本没有内核切换的开销，所以上下文的切换非常快，切换开销比线程更小。

（2）协程不需要多线程的锁机制，因为多个协程从属于一个线程，不存在同时写变量冲突，效率比线程高。

（3）一个线程可以有多个协程。

协程的优势：

（1）协程调用跟切换比线程效率高：协程执行效率极高。协程不需要多线程的锁机制，可以不加锁的访问全局变量，所以上下文的切换非常快。

（2）协程占用内存少：执行协程只需要极少的栈内存（大概是4～5KB），而默认情况下，线程栈的大小为1MB。

（3）切换开销更少：协程直接操作栈基本没有内核切换的开销，所以切换开销比线程少。

# 线程
## 线程之间的通信方式
- 锁机制：包括互斥锁、条件变量、读写锁互斥锁提供了以排他方式防止数据结构被并发修改的方法。读写锁允许多个线程同时读共享数据，而对写操作是互斥的。条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量
- 信号机制(Signal)：类似进程间的信号处理线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。

# 进程

- 每个进程包含独立的地址空间
- 线程没有独立的地址空间，共享所属进程的地址空间
- 操作系统对并发进程的管理是通过对pcb的管理
- C语言程序分为
  - 正文段 代码，赋值数据段，
  - 数据堆段  动态分配的存储区
  - 数据栈段  临时变量


> 进程与线程的区别

1）一个线程从属于一个进程；一个进程可以包含多个线程。

（2）一个线程挂掉，对应的进程挂掉；一个进程挂掉，不会影响其他进程。

（3）进程是系统资源调度的最小单位；线程CPU调度的最小单位。

（4）进程系统开销显著大于线程开销；线程需要的系统资源更少。

（5）进程在执行时拥有独立的内存单元，多个线程共享进程的内存，如代码段、数据段、扩展段；但每个线程拥有自己的栈段和寄存器组。

（6）进程切换时需要刷新TLB并获取新的地址空间，然后切换硬件上下文和内核栈，线程切换时只需要切换硬件上下文和内核栈。

（7）通信方式不一样。

（8）进程适应于多核、多机分布；线程适用于多核
## 进程调度

- 进程的状态
  - 三状态： 就绪态，阻塞态，运行态
  - 五状态： 三 + 新建态和终止态
  - 七状态： 五+ 就绪挂起+阻塞挂起
- sjf算法默认是非抢占式的。
- sjf算法的平均等待时间，平均周转时间最少，前提
  - 所有进程几乎同时到达
  - 所有进程同时可运行
- SRTN最短时间优先算法（抢占式）
- 死锁定理用于检查死锁是否发生

## 进程间的通信
### 匿名管道
>管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。


### 有名管道

匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道(FIFO)。

有名管道不同于匿名管道之处在于它提供了一个 ***路径名*** 与之关联，以有名管道的文件形式存在于文件系统中，这样，即使与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过有名管道相互通信，因此，通过有名管道不相关的进程也能交换数据。值的注意的是，有名管道严格遵循先进先出(first in first out) ,对匿名管道及有名管道的读总是从开始处返回数据，对它们的写则把数据添加到末尾。它们不支持诸如lseek()等文件定位操作。

有名管道的名字存在于 ***文件系统*** 中，内容存放在 ***内存*** 中。

### 信号

信号是Linux系统中用于进程间互相通信或者操作的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。

如果该进程当前并未处于执行状态，则该信号就由内核保存起来，直到该进程恢复执行并传递给它为止。

如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消是才被传递给进程。

信号 ( sinal ) ： 信号是进程间通信机制中唯一的异步通信机制，可以看作是异步通知，通知接收信号的进程有哪些事情发生了。也可以简单理解为信号是某种形式上的软中断。

一般情况下，信号的来源可分为以下三种：

- 硬件方式：除数为零、无效的存储访问等硬件异常产生信号。这些事件通常由硬件(如:CPU)检测到，并将其通知给Linux操作系统内核，然后内核生成相应的信号，并把信号发送给该事件发生时正在进行的程序。
- 软件方式：用户在终端下调用kill命令向进程发送任务信号、进程调用kill或sigqueue函数发送信号、当检测到某种软件条件已经具备时发出信号，如由alarm或settimer设置的定时器超时时将生成SIGALRM信号等多种情景均可产生信号。
- 键盘输入：当用户在终端上按下某键时，将产生信号。如按下组合键Ctrl+C将产生一个SIGINT信号，Ctrl+\产生一个SIGQUIT信号等。
以下列出几个常用的信号：

|信号	|描述|
|----|----|
|SIGHUP	|当用户退出终端时，由该终端开启的所有进程都退接收到这个信号，默认动作为终止进程。|
|SIGINT|	程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl+C)时发出，用于通知前台进程组终止进程。|
|SIGQUIT|	和SIGINT类似, 但由QUIT字符(通常是 `Ctrl+\` )来控制. 进程在因收到SIGQUIT退出时会产生core文件, 在这个意义上类似于一个程序错误信号。|
|SIGKILL|	用来立即结束程序的运行. 本信号不能被阻塞、处理和忽略。|
|SIGTERM|	程序结束(terminate)信号, 与SIGKILL不同的是该信号可以被阻塞和处理。通常用来要求程序自己正常退出。|
|SIGSTOP|	停止(stopped)进程的执行. 注意它和terminate以及interrupt的区别:该进程还未结束, 只是暂停执行. 本信号不能被阻塞, 处理或忽略|


### 消息队列

消息队列是存放在内核中的消息链表，每个消息队列由消息队列标识符表示。

与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。

另外与管道不同的是，消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达。

消息队列特点总结：

1. 消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识.
2. 消息队列允许一个或多个进程向它写入与读取消息.
3. 管道和消息队列的通信数据都是先进先出的原则。
4. 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比FIFO更有优势。
5. 消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺。
6. 目前主要有两种类型的消息队列：POSIX消息队列以及System V消息队列，系统V消息队列目前被大量使用。系统V消息队列是随内核持续的，只有在内核重起或者人工删除时，该消息队列才会被删除。

### 共享内存

进程间本身的内存是相互隔离的，而共享内存机制相当于给两个进程开辟了一块二者均可访问的内存空间，这时，两个进程便可以共享一些数据了。但是，多进程同时占用资源会带来一些意料之外的情况，这时，我们往往会采用上述的信号量来控制多个进程对共享内存空间的访问。

#### 进程之间共享内存的通信方式有什么好处？


采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据：一次从输入文件到共享内存区，另一次从共享内存区到输出文件。

实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。
#### 信号量

信号量主要用来解决进程和线程间并发执行时的同步问题，进程同步是并发进程为了完成共同任务采用某个条件来协调他们的活动，这是进程之间发生的一种直接制约关系。

对信号量的操作分为P操作和V操作，P操作是将信号量的值减一，V操作是将信号量的值加一。当信号量的值小于等于0之后，再进行P操作时，当前进程或线程会被阻塞，直到另一个进程或线程执行了V操作将信号量的值增加到大于0之时。锁也是用的这种原理实现的。

信号量我们需要定义信号量的数量，设定初始值，以及决定何时进行PV操作。

### socket

套接字可以看做是：不同主机之间的进程进行双向通信的端点。（套接字 = IP地址 + 端口号）
## 孤儿进程和僵尸进程

unix/linux中，正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程 到底什么时候结束。 当一个 进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。

- 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
- 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。

## 杀死进程

杀死父进程并不会同时杀死子进程：每个进程都有一个父进程。可以使用 pstree 或 ps 工具来观察这一点
调用 ps 命令可以显示 PID（进程 ID） 和 PPID（父进程 ID）。

杀死父进程后，子进程将会成为孤儿进程，而 init 进程将重新成为它的父进程。

杀死进程组或会话中的所有进程

`$ kill -SIGTERM -- -19701`

这里用一个负数 -19701 向进程组发送信号。如果传递的是一个正数，这个数将被视为进程 ID 用于终止进程。如果传递的是一个负数，它被视为 PGID，用于终止整个进程组。负数来自系统调用的直接定义。

杀死会话中的所有进程与之完全不同。即使是具有会话 ID 的系统，例如 Linux，也没有提供系统调用来终止会话中的所有进程。需要遍历 /proc 输出的进程树，收集所有的 SID，然后一一终止进程。

Pgrep 实现了遍历、收集并通过会话 ID 杀死进程的算法。可以使用以下命令：

`pkill -s <SID>`
## 进程的状态
### 三种状态 
阻塞、运行、和就绪
### 五种状态

- 创建状态：进程在创建时需要申请一个空白PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态
- 就绪状态：进程已经准备好，已分配到所需资源，只要分配到CPU就能够立即运行
- 执行状态：进程处于就绪状态被调度后，进程进入执行状态
- 阻塞状态：正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用
- 终止状态：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行

# 锁
##  悲观锁
悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。

## 乐观锁 
乐观锁总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。

## cas
CAS是英文单词CompareAndSwap的缩写，中文意思是：比较并替换。CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。

- 高并发环境下，对同一个数据的并发读（两边都读出余额是100）与并发写（一个写回28，一个写回38）导致的数据一致性问题。

解决方案是在set写回的时候，加上初始状态的条件compare，只有初始状态不变时，才允许set写回成功，这是一种常见的降低读写锁冲突，保证数据一致性的方法。

# io
## IO多路复用。
IO多路复用是一种同步IO模型，实现一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；没有文件句柄就绪时会阻塞应用程序，交出cpu。

多路是指网络连接，复用指的是同一个线程。

IO多路复用有三种实现方式:`select`, `poll`, `epoll`

(1)select：时间复杂度O(n)，它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。

` int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
select`

函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。

select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。

(2)poll：时间复杂度O(n)，poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。

`int poll (struct pollfd *fds, unsigned int nfds, int timeout);`

不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。

`struct pollfd {     int fd; /* file descriptor */     short events; /* requested events to watch */     short revents; /* returned events witnessed */ };`

pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。

(3)epoll：时间复杂度O(1)，`epoll`可以理解为`event poll`，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以说epoll实际上是事件驱动（每个事件关联上fd）的，此时对这些流的操作都是有意义的。

`int epoll_create(int size)`：创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。

int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)：函数是对指定描述符fd执行op操作。- epfd：是epoll_create()的返回值。- op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。- fd：是需要监听的fd（文件描述符）- epoll_event：是告诉内核需要监听什么事，

int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout)：等待epfd上的io事件，最多返回maxevents个事件。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时


select poll 消息需要传递到内核空间，需要内核拷贝动作

epoll 通过内核和用户空间共享一块内存来实现

### select poll，epoll的区别
>poll
poll将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。

它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有缺点：

大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。

poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

>epoll

epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。

epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。其优点有：

没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。

效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。

内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销

> select 
select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。

select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。

内核需要传递消息到用户空间，需要内存拷贝

>epoll
相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。

epoll能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。

效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。


### epoll
epoll对文件描述符的操作有两种模式：`LT（level trigger` 和ET`（edge trigger）`。LT模式是默认模式，LT模式与ET模式的区别如下：

LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。

ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。

LT模式

LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。

ET模式

ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)。

ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

# ip
##  如何在Linux上配置一个IP地址，如果给定端口号如何解析出域名？
配置Linux系统的IP地址的方法，主要有以下三种：

- ifconfig :ifconfig 命令主要是用来查看网卡的配置信息，因为用它来配置网卡的IP地址时，只会临时生效（Linux服务器重启后就会失效）
- setup:setup 命令是 redhat 系列的linux系统（如CentOS）中专有的命令工具。可以使用 setup 命令，来对网络配置中的IP地址、子网掩码、默认网关、DNS服务器进行设置。而且，setup 网络配置工具设置的IP地址会永久生效。
- 修改网卡的配置文件 :直接修改网卡的配置文件，设置方法有两种：
  - 自动获取动态IP地址
  - 手工配置静态的IP地址


使用dig命令解析域名
## Linux的静态网络怎么配置
网络配置的配置文件在 `/etc/sysconfig/network-scripts/` 下，文件名前缀为ifcfg-后面跟的就是网卡的名称，可以使用ifconfig查看，也可以使用命令： `ls /etc/sysconfig/network-scripts/ifcfg-*` 列出所有的设备配置文件，

ifcfg-eno16777984这个文件，ifcfg-lo是本地回环地址的配置文件，所有计算机都有，不用动他，

现在使用： `vim /etc/sysconfig/network-scripts/ifcfg-eno16777984` 打开配置文件进行编辑，默认情况是dhcp动态获取的

这时候如果想修改成静态的，首先把`BOOTPROTO="dhcp"`改成`BOOTPROTO="static"`表示静态获取，然后在最后追加比如下面的配置

`BROADCAST=192.168.1.255 IPADDR=192.168.1.33 NETMASK=255.255.255.0 GATEWAY=192.168.1.1`

BROADCAST设置的是局域网广播地址，IPADDR就是静态IP，NETMASK是子网掩码，GATEWAY就是网关或者路由地址；需要说明，原来还有个NETWORK配置的是局域网网络号，这个是ifcalc自动计算的，所以这里配置这些就足够了
配置完成之后保存退出，

设置完毕，然后使用命令： `/etc/init.d/network restart` 或者 `service network restart` 重启网络服务，重启后如果路由配置了支持静态IP，那么linux就能获取到刚才配置的IP地址，这样静态IP就配置成功

## dns
### dns使用的协议
>DNS在进行区域传输的时候使用TCP协议，其它时候则使用UDP协议；

DNS的规范规定了2种类型的DNS服务器，一个叫主DNS服务器，一个叫辅助DNS服务器。在一个区中主DNS服务器从自己本机的数据文件中读取该区的DNS数据信息，而辅助DNS服务器则从区的主DNS服务器中读取该区的DNS数据信息。当一个辅助DNS服务器启动时，它需要与主DNS服务器通信，并加载数据信息，这就叫做区传送（zone transfer）。 

> 为什么既使用TCP又使用UDP？

  UDP报文的最大长度为512字节，而TCP则允许报文长度超过512字节。当DNS查询超过512字节时，协议的TC标志出现删除标志，这时则使用TCP发送。通常传统的UDP报文一般不会大于512字节。 

区域传送时使用TCP，主要有以下两点考虑：

辅域名服务器会定时（一般时3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。区域传送将使用TCP而不是UDP，因为数据同步传送的数据量比一个请求和应答的数据量要多得多。 

TCP是一种可靠的连接，保证了数据的准确性。 

域名解析时使用UDP协议： 

客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过TCP三次握手，这样DNS服务器负载更低，响应更快。虽然从理论上说，客户端也可以指定向DNS服务器查询的时候使用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持UDP查询包。

# 内存管理

- 形成逻辑地址是在链接阶段
- 程序在进行io操作时不能撤出主存，有系统缓冲区是可以
- 覆盖和交换是为进了解决内存不足的问题，节省内存空间
- 分区分配内存的主要保护措施是界地址保护
- 分段管理有利于程序的动态链接
- 分区存储管理的代价最小
- 重定位是逻辑地址到物理地址
- 分段是二维地址结构，分页是一维
- 每个进程都有一个属于自己的页表

## 内存常见名词
1. 虚拟内存

物理内存是有限的（即使支持了热插拔）、非连续的，不同的CPU架构对物理内存的组织都不同。这使得直接使用物理内存非常复杂，为了降低使用内存的复杂度，引入了虚拟内存机制。

虚拟内存抽象了应用程序物理内存的细节，只允许物理内存保存所需的信息（按需分页），并提供了一种保护和控制进程间数据共享数据的机制。有了虚拟内存机制之后，每次访问可以使用更易理解的虚拟地址，让CPU转换成实际的物理地址访问内存，降低了直接使用、管理物理内存的门槛。

物理内存按大小被分成页框、页，每块物理内存可以被映射为一个或多个虚拟内存页。这块映射关系，由操作系统的页表来保存，页表是有层级的。层级最低的页表，保存实际页面的物理地址，较高层级的页表包含指向低层级页表的物理地址，指向顶级的页表的地址，驻留在寄存器中。当执行地址转换时，先从寄存器获取顶级页表地址，然后依次索引，找到具体页面的物理地址。

2. 大页机制

虚拟地址转换的过程中，需要好几个内存访问，由于内存访问相对CPU较慢，为了提高性能，CPU维护了一个TLB地址转换的cache，TLB是比较重要且珍稀的缓存，对于大内存工作集的应用程序，会因TLB命中率低大大影响到性能。

为了减少TLB的压力，增加TLB缓存的命中率，有些系统会把页的大小设为MB或者GB，这样页的数目少了，需要转换的页表项也小了，足以把虚拟地址和物理地址的映射关系，全部保存于TLB中。

3. 区域概念

通常硬件会对访问不同的物理内存的范围做出限制，在某些情况下设备无法对所有的内存区域做DMA。在其他情况下，物理内存的大小也会超过了虚拟内存的最大可寻址大小，需要执行特殊操作，才能访问这些区域。这些情况下，Linux对内存页的可能使用情况将其分组到各自的区域中（方便管理和限制）。比如ZONE_DMA用于指明哪些可以用于DMA的区域，ZONE_HIGHMEM包含未永久映射到内核地址空间的内存，ZONE_NORMAL标识正常的内存区域。

4. 节点

多核CPU的系统中，通常是NUMA系统（非统一内存访问系统）。在这种系统中，内存被安排成具有不同访问延迟的存储组，这取决于与处理器的距离。每一个库，被称为一个节点，每个节点Linux构建了一个独立的内存管理子系统。一个节点有自己的区域集、可用页和已用页表和各种统计计数器。

5. page cache

从外部存储介质中加载数据到内存中，这个过程是比较耗时的，因为外部存储介质读写性能毫秒级。为了减少外部存储设备的读写，Linux内核提供了Page cache。最常见的操作，每次读取文件时，数据都会被放入页面缓存中，以避免后续读取时所进行昂贵的磁盘访问。同样，当写入文件时，数据被重新放置在缓存中，被标记为脏页，定期的更新到存储设备上，以提高读写性能。

6. 匿名内存

匿名内存或者匿名映射表示不受文件系统支持的内存，比如程序的堆栈隐式创立的，或者显示通过mmap创立的。

7. 内存回收

贯穿系统的生命周期，一个物理页可存储不同类型的数据，可以是内核的数据结构，或是DMA访问的buffer，或是从文件系统读取的数据，或是用户程序分配的内存等。

根据页面的使用情况，Linux内存管理对其进行了不同的处理，可以随时释放的页面，称之为可回收页面，这类页面为：页面缓存或者是匿名内存（被再次交换到硬盘上）

大多数情况下，保存内部内核数据并用DMA缓冲区的页面是不能重新被回收的，但是某些情况下，可以回收使用内核数据结构的页面。例如：文件系统元数据的内存缓存，当系统处于内存压力情况下，可以从主存中丢弃它们。

释放可回收的物理内存页的过程，被称之为回收，可以同步或者异步的回收操作。当系统负载增加到一定程序时，kswapd守护进程会异步的扫描物理页，可回收的物理页被释放，并逐出备份到存储设备。

8. compaction

系统运行一段时间，内存就会变得支离破碎。虽然使用虚拟村内可以将分散的物理页显示为连续的物理页，但有时需要分配较大的物理连续内存区域。比如设备驱动程序需要一个用于DMA的大缓冲区时，或者大页内存机制分页时。内存compact可以解决了内存碎片的问题，这个机制将被占用的页面，从内存区域合适的移动，以换取大块的空闲物理页的过程，由kcompactd守护进程完成。

9. OOM killer

机器上的内存可能会被耗尽，并且内核将无法回收足够的内存用于运行新的程序，为了保存系统的其余部分，内核会调用OOM killer杀掉一些进程，以释放内存。

段页机制

段页机制是操作系统管理内存的一种方式，简单的来说，就是如何管理、组织系统中的内存。要理解这种机制，需要了解一下内存寻址的发展历程。

直接寻址：早期的内存很小，通过硬编码的形式，直接定位到内存地址。这种方式有着明显的缺点：可控性弱、难以重定位、难以维护

分段机制：8086处理器，寻址空间达到1MB，即地址线扩展了20位，由于制作20位的寄存器较为困难，为了能在16位的寄存器的基础上，寻址20位的地址空间，引入了段的概念，即内存地址=段基址左移4位+偏移

分页机制：随着寻址空间的进一步扩大、虚拟内存技术的引入，操作系统引入了分页机制。引入分页机制后，逻辑地址经过段机制转换得到的地址仅是中间地址，还需要通过页机制转换，才能得到实际的物理地址。逻辑地址 -->(分段机制) 线性地址 -->(分页机制) 物理地址。

## 内存回收
内存回收方式有三种：
基于LRU（Least Recently Used）算法，回收缓存；基于Swap机制，回收不常访问的匿名页；基于OOM（Out of Memory）机制，杀掉占用大量内存的进程。

LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中：active记录活跃的内存页；inactive 记录非活跃的内存页。

malloc()对应到系统调用上两种实现方式，分别为brk()和mmap()来分配；小块内存（小于128K）使用brk()来分配，大块内存（大于 128K），则直接使用内存映射mmap()


`cat /proc/meminfo | grep -i active | sort`可查看active、inactive大小
## 虚拟存储

- 缺页中断之后应该执行的是被中断的那一条指令
- 虚拟存储器的容量是由计算机的地址结构决定的
- 所有置换策略都有可能引起抖动
- lru算法（最近未使用）算法耗费高的原因是需要对所有的页进行排序
- 工作集的窗口时某时刻之前的

### 虚拟内存模型
人们之所以要创建一个虚拟地址空间，目的是为了解决进程地址空间隔离的问题

虚拟内存分成五大区，分别为栈区、堆区、全局区（静态区）、文字常量区（常量存储区）、程序代码区。五大区特性如下：

- 栈区（stack）： 由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。
- 堆区（heap）： 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表。
- 全局区（静态区）（static）：全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域， 未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。程序结束后由系统释放。
- 文字常量区（常量存储区） ：常量字符串就是放在这里的。 程序结束后由系统释放。这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改。
- 程序代码区：存放函数体的二进制代码。

linux 32位 一共4g 内存 高1g位内核空间，低3g位用户空间

## 内存映射
### mmap
常规文件操作为了提高读写效率和保护磁盘，使用了页缓存机制。这样造成读文件时需要先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中
**mmap的优势在于，把磁盘文件与进程虚拟地址做了映射，这样可以跳过page cache，只使用一次数据拷贝。**

### 缓存溢出
#### 防止缓存溢出
- 编译时防御系统，目的是强化系统以抵御潜伏于新程序中的恶意攻击
- 运行时预防系统，目的是检测并终止现有程序中的恶意攻击
# 文件管理

- 对用户来说文件系统是为了实现对文件的按名索取
- 打开文件的主要工作就是把文件的目录复制到内存指定的区域
- 在unix中输入输出设备属于特殊文件
- 多级目录结构解决了命名冲突
- 文件被进程首次打开时，系统首先要将文件控制块读到内存中。

## 链接
### 软连接和硬链接的区别


- 1 软链接可以为文件和目录（哪怕是不存在的）创建链接；硬链接只能为文件创建链接。 
- 2 软链接可以跨文件系统；硬链接必须是同一个文件系统 
- 3 硬链接因为只是文件的一个别名，所以不重复占用内存；软链接因为只是一个访问文件的快捷方式文件，文件内只包含快捷指向信息，所以占用很小的内存。 
- 4 软链接的文件权限和源文件可以不一样；硬链接文件权限肯定是一样的，因为他们本来就是一个文件的不同名称而已。
- 5 软链接文件的源文件必须写成绝对路径，而不能写成相对路径（硬链接没有这样的要求）；否则软链接文件会报错
## 磁盘管理

- 直接存取即随机存取，连续分配和索引分配都适合，链接分配不适合
- 散列法不适合顺序查找和枚举文件，线性检索适合常用
- 磁带一般只能顺序检索，顺序存储，除非说是能倒带

- 只有先来先服务绝不会导致磁臂黏着

# 设备管理

- 设备映射表dmt是用来管理逻辑设备和物理设备之间的映射关系的。
- 分配共享设备不会引起死锁
- 共享设备必须是可寻址的和可随机访问的。
- 逻辑设备可以把一个物理设备转化为多个逻辑设备
- 字节多路通道用于来连接大量的低速和中速i/o设备
- 设备分配时一般不考虑及时性问题
- 系统为设备的统一编号称为绝对号
- 键盘是中断方式工作外设
- 计算磁盘号，磁头号，扇区号是由磁盘驱动程序完成的。
- 多个并发进程共享可以使用缓冲池技术
- 缓冲池管理最重要的问题是实现进程访问缓冲区的同步
- 图形用户页面下，鼠标可以使用缓冲技术
- 虚拟设备是靠spooling技术实现的
- spooling技术的主要目的是为了提高设备的占有率
- spooling技术的基本条件是要有大容量高速度的外存作为输入井和输出井
- spooling技术将一个独占设备虚拟成一个共享设备供多个进程使用


### 软中断和硬中断有什么区别？


硬中断

    由与系统相连的外设(比如网卡、硬盘)自动产生的。主要是用来通知操作系统外设状态的变化。比如当网卡收到数据包的时候，就会发出一个中断。我们通常所说的中断指的是硬中断(hardirq)。

软终端

    为了满足实时系统的要求，中断处理应该是越快越好。Linux为了实现这个特点，当中断发生的时候，硬中断处理那些短时间就可以完成的工作，而将那些处理事件比较长的工作，放到中断之后来完成，也就是软中断(softirq)来完成。

中断嵌套

    Linux下硬中断是可以嵌套的，但是没有优先级的概念，也就是说任何一个新的中断都可以打断正在执行的中断，但同种中断除外。软中断不能嵌套，但相同类型的软中断可以在不同CPU上并行执行。

软中断与硬中断之间的区别

（1）硬中断是由外部事件引起的因此具有随机性和突发性；软中断是执行中断指令产生的，无外面事件中断请求信号，因此软中断的发生不是随机的而是由程序安排好的；

（2）硬中断的中断号是由中断控制器提供的；软中断的中断号是由指令直接给出的，无需使用中断控制器。

（3）硬中断的中断响应周期，CPU需要发中断回合信号；软中断的中断响应周期，CPU不需要发中断回合信号。

（4）硬中断是可屏蔽的；软中断是不可屏蔽的。

