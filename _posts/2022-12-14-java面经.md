---
layout: post
title: java面经
categories: study
tags : java
toc: true
---

# java基础
## 
>重写和重载的区别
重载(Overload)： 在一个类中，同名的方法如果有不同的参数列表（比如参数类型不同、参数个数不同）则视为重载。

重写(Override)： 从字面上看，重写就是 重新写一遍的意思。其实就是在子类中把父类本身有的方法重新写一遍。子类继承了父类的方法，但有时子类并不想原封不动的继承父类中的某个方法，所以在方法名，参数列表，返回类型都相同(子类中方法的返回值可以是父类中方法返回值的子类)的情况下， 对方法体进行修改，这就是重写。但要注意子类方法的访问修饰权限不能小于父类的。
## 常用类
> 使用字符串时，new和""推荐使用哪种方式？

先看看 "hello" 和 new String("hello") 的区别：

当Java程序直接使用 "hello" 的字符串直接量时，JVM将会使用常量池来管理这个字符串；

当使用 new String("hello") 时，JVM会先使用常量池来管理 "hello" 直接量，再调用String类的构造器来创建一个新的String对象，新创建的String对象被保存在堆内存中。

显然，采用new的方式会多创建一个对象出来，会占用更多的内存，所以一般建议使用直接量的方式创建字符串。

>说一说你对字符串拼接的理解

拼接字符串有很多种方式，其中最常用的有4种，下面列举了这4种方式各自适合的场景。

+ 运算符：如果拼接的都是字符串直接量，则适合使用 + 运算符实现拼接；

StringBuilder：如果拼接的字符串中包含变量，并不要求线程安全，则适合使用StringBuilder；

StringBuffer：如果拼接的字符串中包含变量，并且要求线程安全，则适合使用StringBuffer；

String类的concat方法：如果只是对两个字符串进行拼接，并且包含变量，则适合使用concat方法；

> 介绍一下类型擦除

在严格的泛型代码里，带泛型声明的类总应该带着类型参数。但为了与老的Java代码保持一致，也允许在使用带泛型声明的类时不指定实际的类型。如果没有为这个泛型类指定实际的类型，此时被称作raw type（原始类型），默认是声明该泛型形参时指定的第一个上限类型。

当把一个具有泛型信息的对象赋给另一个没有泛型信息的变量时，所有在尖括号之间的类型信息都将被扔掉。比如一个 List<String> 类型被转换为List，则该List对集合元素的类型检查变成了泛型参数的上限（即Object）。

上述规则即为泛型擦除，可以通过下面代码进一步理解泛型擦除：

`List<String> list1 = ...; List list2 = list1; //`

> java的四种引用方式
Java对象的四种引用方式分别是强引用、软引用、弱引用、虚引用，具体含义如下：

强引用：这是Java程序中最常见的引用方式，即程序创建一个对象，并把这个对象赋给一个引用变量，程序通过该引用变量来操作实际的对象。当一个对象被一个或一个以上的引用变量所引用时，它处于可达状态，不可能被系统垃圾回收机制回收。

软引用：当一个对象只有软引用时，它有可能被垃圾回收机制回收。对于只有软引用的对象而言，当系统内存空间足够时，它不会被系统回收，程序也可使用该对象。当系统内存空间不足时，系统可能会回收它。软引用通常用于对内存敏感的程序中。

弱引用：弱引用和软引用很像，但弱引用的引用级别更低。对于只有弱引用的对象而言，当系统垃圾回收机制运行时，不管系统内存是否足够，总会回收该对象所占用的内存。当然，并不是说当一个对象只有弱引用时，它就会立即被回收，正如那些失去引用的对象一样，必须等到系统垃圾回收机制运行时才会被回收。

虚引用：虚引用完全类似于没有引用。虚引用对对象本身没有太大影响，对象甚至感觉不到虚引用的存在。如果一个对象只有一个虚引用时，那么它和没有引用的效果大致相同。虚引用主要用于跟踪对象被垃圾回收的状态，虚引用不能单独使用，虚引用必须和引用队列联合使用

> copyonwriteArraryList的底层

CopyOnWriteArrayList添加元素时，会复制一个新的数组，写操作在新数组上进行，读操作在原数组上进行

并且，写操作会加锁，防止出现并发写入丢失数据的问题

写操作结束之后会把原数组指向新数组

CopyOnWriteArrayList允许在写操作时来读取数据，大大提高了读的性能，因此适合读多写少的应用场景，但是CopyOnWriteArrayList会比较占内存，同时可能读到的数据不是实时最新的数据，所以不适合实时性要求很高的场景

> ReentrantLock的tryLock和Lock的区别

tryLock会尝试加锁，加不到锁也不会阻塞进程，加到锁会返回true否则返回false

lock会一直加锁，加不到就阻塞线程，没有返回值
## 类，对象

> 全局变量，局部变量的存储
- 实例变量存储在对象所在的堆内存中。
- 类变量存储在方法区中。
- 局域变量存储在栈内存中


### equals与HashCode

> hashcode方法的作用

1.hashcode特性体现主要在它的查找快捷性，在Set和Map这种使用哈希表结构存储数据的集合中。HashCode方法的就大大体现了它的价值，主要用于在这些集合中确定对象在整个哈希表中存储的区域。
2.如果两个对象相同，则着两个对象的equals方法返回的值一定为true，两个对象的HashCode方法返回的值也一定相同。
3.如果两个对象返回的HashCode的值相同，但不能够说明这两个对象的equals方法返回的值就一定为true，只能说明这两个对象在存储在哈希表中的一个桶中

> 如果一个对象equals方法被重写，那么该对象的HashCode方法也应该被重写

在java中equals方法用于判断两个对象是否相等，而HashCode方法在java中主要由于哈希算法中的寻域的功能（也就是寻找数据应该存储的区域的）。在类似于set和map集合的结构中，java为了提高在集合中查询匹配元素的效率问题，引入了哈希算法，通过某种算法及我们的HashCode方法得到对象的hash码，再通过hash码推算出数据应该存储的位置。然后再进行equals操作进行匹配，减少了比较次数，提高了效率。在集合做了优化之后进行判断元素相等的过程是这样的，首先判断两个对象的HashCode方法返回的值是否相等，如果相等然后再判断两个对象的equals方法，如果HashCode方法返回的值不相等，则直接会认为两个对象不相等，不进行equals方法的判断。有这样一个场景有两个Student对象，equals方法认为如果两个对象的学号相同则认为这两个对象相同。可是如果没有重写HashCode方法只重写了equals方法，此刻并不能实现我们的要求，它首先会判断HashCode方法返回的值是否相等，由于我们没有重写HashCode方法，此时返回的值是不同的，因此不会去判断我们重写的equals方法。而如果重写HashCode方法不重写equals方法也是同样的效果，不重写equals方法实际是调用Object方法中的equals方法，判断的是两个对象的堆内地址。而我们重写的HashCode方法认为相等的两个对象在equals方法处并不相等。因此重写equals方法时一定也要重写HashCode方法，重写HashCode方法时也应该重写equals方法

> 为什么equals方法不相等而HashCode方法返回的值却有可能相同呢？

A：HashCode方法实际上是通过一种算法得到一个对象的hash码，这个hash码是用来确定该对象在哈希表中具体的存储区域的。返回的hash码是int类型的所以它的数值范围为[-2147483648-+2147483647]之间的，而超过这个范围，实际会产生溢出，溢出之后的值实际在计算机中存的也是这个范围的。比如最大值2147483647+1之后并不是在计算机中不存储了，它实际在计算机中存储的是-2147483648。在java中对象可以有很多很多通过new关键字来产生。而hash码也是通过特定算法得到的，所以很难或者说几乎没有什么算法在这个范围内在这个情况下不会不产生相同的hash码的。也就是说在上述情况下肯定是会发生哈希碰撞的，因此不同对象可能有相同的HashCode的返回值。也有人说Object方法中的HashCode方法是通过内存地址得来的，是唯一的。可是HashCode方法是共有的，也就意味着它是可以被程序员重写的。因此不同环境下实现HashCode的算法可能不同。因此equals方法返回结果不相等，而HashCode方法返回的值却有可能相同！

### HashMap的线程安全问题
>HashMap是线程不安全的

多个相同key的同时插入，多个线程同时检测到需要扩容，HashMap 在并发执行 put 操作时会引起死循环，导致 CPU 利用率接近100%。因为多线程会导致 HashMap 的 Node 链表形成环形数据结构，一旦形成环形数据结构，Node 的 next 节点永远不为空，就会在获取 Node 时产生死循环

> 如何在线程安全的时候使用

换用线程安全的HasHMap
Hashtable
ConcurrentHashMap
Synchronized Map
使用Collections将HashMap包装成线程安全的Map。
### HashMap的链表和红黑树转化问题
>HashMap 链表和红黑树的转换

红黑树的平均查找长度是log(n)，长度为8，查找长度为log(8)=3，链表的平均查找长度为n/2，当长度为8时，平均查找长度为8/2=4，这才有转换成树的必要；链表长度如果是小于等于6，6/2=3，虽然速度也很快的，但是转化为树结构和生成树的时间并不会太短。

还有选择6和8的原因是：

中间有个差值7可以防止链表和树之间频繁的转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个`HashMap`不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低下.

链表转换为红黑树的最终目的，是为了解决在map中元素过多，hash冲突较大，而导致的读写效率降低的问题。在源码的putVal方法中，有关红黑树结构化的分支为：

>HashMap的底层

HashMap 的底层实现是数组+链表+红黑树的形式的，同时它的数组的默认初始容量是 16、***扩容因子***为 0.75，每次采用 2 倍的扩容。

在 JDK1.7 以及前是在头结点插入的，在 JDK1.8 之后是在尾节点插入的
### HashTable与ConcurrentHashMap
>效率低下的HashTable容器

`HashTable`容器使用`synchronized`来保证线程安全，但在线程竞争激烈的情况下`HashTable`的效率非常低下。因为当一个线程访问`HashTable`的同步方法时，其他线程访问`HashTable`的同步方法时，可能会进入阻塞或轮询状态。如线程1使用`put`进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低

>ConcurrentHashMap的锁分段技术

`HashTable`容器在竞争激烈的并发环境下表现出效率低下的原因，是因为所有访问`HashTable`的线程都必须竞争同一把锁，那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是`ConcurrentHashMap`所使用的锁分段技术，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。

`ConcurrentHashMap`是由`Segment`数组结构和`HashEntry`数组结构组成。`Segment`是一种可重入锁`ReentrantLock`，在`ConcurrentHashMap`里扮演锁的角色，`HashEntry`则用于存储键值对数据。一个`ConcurrentHashMap`里包含一个`Segment`数组，`Segment`的结构和HashMap类似，是一种数组和链表结构， 一个`Segment`里包含一个`HashEntry`数组，每个`HashEntry`是一个链表结构的元素， 每个Segment守护着一个`HashEntry`数组里的元素,当对`HashEntry`数组的数据进行修改时，必须首先获得它对应的Segment锁。


如何扩容。扩容的时候首先会创建一个两倍于原容量的数组，然后将原数组里的元素进行再hash后插入到新的数组里。为了高效`ConcurrentHashMap`不会对整个容器进行扩容，而只对某个`segment`进行扩容

如果我们要统计整个`ConcurrentHashMap`里元素的大小，就必须统计所有`Segment`里元素的大小后求和。`Segment`里的全局变量count是一个volatile变量，那么在多线程场景下，我们是不是直接把所有Segment的count相加就可以得到整个`ConcurrentHashMap`大小了呢？不是的，虽然相加时可以获取每个`Segment`的count的最新值，但是拿到之后可能累加前使用的count发生了变化，那么统计结果就不准了。所以最安全的做法，是在统计size的时候把所有`Segment`的put，remove和clean方法全部锁住，但是这种做法显然非常低效。

因为在累加count操作过程中，之前累加过的count发生变化的几率非常小，所以ConcurrentHashMap的做法是先尝试2次通过不锁住Segment的方式来统计各个Segment大小，如果统计的过程中，容器的count发生了变化，则再采用加锁的方式来统计所有Segment的大小。

那么`ConcurrentHashMap`是如何判断在统计的时候容器是否发生了变化呢？使用modCount变量，在put , remove和clean方法里操作元素前都会将变量modCount进行加1，那么在统计size前后比较modCount是否发生变化，从而得知容器的大小是否发生变化
JDK 1.8中的实现：

JDK1.8 的实现已经摒弃了 Segment 的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 Synchronized 和 CAS 来操作，整个看起来就像是优化过且线程安全的 HashMap，虽然在 JDK1.8 中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本。

1.8版本的ConcurrentHashMap不再基于Segment实现,当某个线程进行put时，如果发现ConcurrentHashMap正在进行扩容那么该线程一起进行扩容,如果某个线程put时，发现没有正在进行扩容，则将key-value添加到ConcurrentHashMap中，然后判断是否超过阈值，超过了则进行扩容,ConcurrentHashMap是支持多个线程同时扩容的,扩容之前也先生成一个新的数组.在转移元素时，先将原数组分组，将每组分给不同的线程来进行元素的转移，每个线程负责一组或多组的元素转移工作



> concurrentHaahMap是怎么实现分段分组的
get操作：

Segment的get操作实现非常简单和高效，先经过一次再散列，然后使用这个散列值通过散列运算定位到 Segment，再通过散列算法定位到元素。get操作的高效之处在于整个get过程都不需要加锁，除非读到空的值才会加锁重读。原因就是将使用的共享变量定义成 volatile 类型。

put操作：

当执行put操作时，会经历两个步骤：

判断是否需要扩容；

定位到添加元素的位置，将其放入 HashEntry 数组中。

插入过程会进行第一次 key 的 hash 来定位 Segment 的位置，如果该 Segment 还没有初始化，即通过 CAS 操作进行赋值，然后进行第二次 hash 操作，找到相应的 HashEntry 的位置，这里会利用继承过来的锁的特性，在将数据插入指定的 HashEntry 位置时（尾插法），会通过继承 ReentrantLock 的 tryLock() 方法尝试去获取锁，如果获取成功就直接插入相应的位置，如果已经有线程获取该Segment的锁，那当前线程会以自旋的方式去继续的调用 tryLock() 方法去获取锁，超过指定次数就挂起，等待唤醒。

> BlockingQueue是怎么实现的？
参考答案

BlockingQueue是一个接口，它的实现类有ArrayBlockingQueue、DelayQueue、 LinkedBlockingQueue、PriorityBlockingQueue、SynchronousQueue等。它们的区别主要体现在存储结构上或对元素操作上的不同，但是对于put与take操作的原理是类似的。下面以ArrayBlockingQueue为例，来说明BlockingQueue的实现原理。

首先看一下ArrayBlockingQueue的构造函数，它初始化了put和take函数中用到的关键成员变量，这两个变量的类型分别是ReentrantLock和Condition。ReentrantLock是AbstractQueuedSynchronizer（AQS）的子类，它的newCondition函数返回的Condition实例，是定义在AQS类内部的ConditionObject类，该类可以直接调用AQS相关的函数。
```java
public ArrayBlockingQueue(int capacity, boolean fair) {      if (capacity <= 0)          throw new IllegalArgumentException();      this.items = new Object[capacity];      lock = new ReentrantLock(fair);      notEmpty = lock.newCondition();      notFull = lock.newCondition();  }
```
put函数会在队列末尾添加元素，如果队列已经满了，无法添加元素的话，就一直阻塞等待到可以加入为止。函数的源码如下所示。我们会发现put函数使用了wait/notify的机制。与一般生产者-消费者的实现方式不同，同步队列使用ReentrantLock和Condition相结合的机制，即先获得锁，再等待，而不是synchronized和wait的机制。

```java
public void put(E e) throws InterruptedException {      checkNotNull(e);      final ReentrantLock lock = this.lock;      lock.lockInterruptibly();      try {          while (count == items.length)              notFull.await();          enqueue(e);      } finally {          lock.unlock();      }  }
```
再来看一下消费者调用的take函数，take函数在队列为空时会被阻塞，一直到阻塞队列加入了新的元素。

## 流
> 介绍一下java的nio
Java的NIO主要由三个核心部分组成：Channel、Buffer、Selector。

基本上，所有的IO在NIO中都从一个Channel开始，数据可以从Channel读到Buffer中，也可以从Buffer写到Channel中。Channel有好几种类型，其中比较常用的有FileChannel、DatagramChannel、SocketChannel、ServerSocketChannel等，这些通道涵盖了UDP和TCP网络IO以及文件IO。

Buffer本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。Java NIO里关键的Buffer实现有CharBuffer、ByteBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer。这些Buffer覆盖了你能通过IO发送的基本数据类型，即byte、short、int、long、float、double、char。

Buffer对象包含三个重要的属性，分别是capacity、position、limit，其中position和limit的含义取决于Buffer处在读模式还是写模式。但不管Buffer处在什么模式，capacity的含义总是一样的。

capacity：作为一个内存块，Buffer有个固定的最大值，就是capacity。Buffer只能写capacity个数据，一旦Buffer满了，需要将其清空才能继续写数据往里写数据。

position：当写数据到Buffer中时，position表示当前的位置。初始的position值为0。当一个数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity–1。当读取数据时，也是从某个特定位置读。当将Buffer从写模式切换到读模式，position会被重置为0。当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。

limit：在写模式下，Buffer的limit表示最多能往Buffer里写多少数据，此时limit等于capacity。当切换Buffer到读模式时， limit表示你最多能读到多少数据，此时limit会被设置成写模式下的position值
## 动态代理的两种方式
- JDK动态代理：利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。
- CGlib动态代理：利用ASM（开源的Java字节码编辑库，操作字节码）开源包，将代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。

1.JDK代理使用的是反射机制实现aop的动态代理，CGLIB代理使用字节码处理框架asm，通过修改字节码生成子类。所以jdk动态代理的方式创建代理对象效率较高，执行效率较低，cglib创建效率较低，执行效率高；

2.JDK动态代理机制是委托机制，具体说动态实现接口类，在动态生成的实现类里面委托hanlder去调用原始实现类方法，CGLIB则使用的继承机制，具体说被代理类和代理类是继承关系，所以代理类是可以赋值给被代理类的，如果被代理类有接口，那么代理类也可以赋值给接口

JDK代理只能对实现接口的类生成代理；CGlib是针对类实现代理，对指定的类生成一个子类，并覆盖其中的方法，这种通过继承类的实现方式，不能代理final修饰的

## 线程
>ThreadLocal底层
线程本地存储机制
底层是一个ThreadLocalMap，用来保存黁每个线程内部的数据。键值和对象。有时候会发生内存泄漏问题再执行玩任务之后，尤其是线程池的线程可以进行一下ThreadLocal .remove方法清理一下

### 线程池的参数和创建线程的方式
> 线程池为什么是先添加队列而不是先创建最大线程
队列满了之后才会创建新的线程
> 线程池的参数

```java
public ThreadPoolExecutor(
    int corePoolSize,
    int maximumPoolSize,
    loog keepAliveTime,
    TimeUnit unit,
    BlockingQueue<Runnable> workQueue,
    ThreadFactory threadFacrory,
    RejectedExecutionHandler handler

)
```
线程池的构造函数有7个参数，分别是`corePoolSize`、`maximumPoolSize`、`keepAliveTime`、`unit`、`workQueue`、`threadFactory`、`handler`

- 一、`corePoolSize` 线程池核心线程大小

线程池中会维护一个最小的线程数量，即使这些线程处理空闲状态，他们也不会被销毁，除非设置了`allowCoreThreadTimeOut`。这里的最小线程数量即是corePoolSize。任务提交到线程池后，首先会检查当前线程数是否达到了`corePoolSize`，如果没有达到的话，则会创建一个新线程来处理这个任务。

- 二、`maximumPoolSize` 线程池最大线程数量

当前线程数达到corePoolSize后，如果继续有任务被提交到线程池，会将任务缓存到工作队列（后面会介绍）中。如果队列也已满，则会去创建一个新线程来出来这个处理。线程池不会无限制的去创建新线程，它会有一个最大线程数量的限制，这个数量即由maximunPoolSize指定。

- 三、`keepAliveTime` 空闲线程存活时间

一个线程如果处于空闲状态，并且当前的线程数量大于`corePoolSize`，那么在指定时间后，这个空闲线程会被销毁，这里的指定时间由keepAliveTime来设定

- 四、`unit` 空闲线程存活时间单位

`keepAliveTime`的计量单位

- 五、`workQueue` 工作队列

新任务被提交后，会先进入到此工作队列中，任务调度时再从队列中取出任务。jdk中提供了四种工作队列：

 - `①ArrayBlockingQueue`

基于数组的有界阻塞队列，按FIFO排序。新任务进来后，会放到该队列的队尾，有界的数组可以防止资源耗尽问题。当线程池中线程数量达到`corePoolSize`后，再有新任务进来，则会将任务放入该队列的队尾，等待被调度。如果队列已经是满的，则创建一个新线程，如果线程数量已经达到`maxPoolSize`，则会执行**拒绝策略**。

 - `②LinkedBlockingQuene`

基于链表的无界阻塞队列（其实最大容量为`Interger.MAX`），按照`FIFO`排序。由于该队列的近似无界性，当线程池中线程数量达到`corePoolSize`后，再有新任务进来，会一直存入该队列，而基本不会去创建新线程直到maxPoolSize（很难达到Interger.MAX这个数），因此使用该工作队列时，参数`maxPoolSize`其实是不起作用的。

 - `③SynchronousQuene`

一个不缓存任务的阻塞队列，生产者放入一个任务必须等到消费者取出这个任务。也就是说新任务进来时，不会缓存，而是直接被调度执行该任务，如果没有可用线程，则创建新线程，如果线程数量达到maxPoolSize，则执行拒绝策略。

 - `④PriorityBlockingQueue`

具有优先级的无界阻塞队列，优先级通过参数Comparator实现。

- 六、`threadFactory` 线程工厂

创建一个新线程时使用的工厂，可以用来设定线程名、是否为`daemon`线程等等

- 七、`handler` 拒绝策略

当工作队列中的任务已到达最大限制，并且线程池中的线程数量也达到最大限制，这时如果有新任务提交进来，该如何处理呢。这里的拒绝策略，就是解决这个问题的，jdk中提供了4中拒绝策略：

 - `①CallerRunsPolicy`

该策略下，在调用者线程中直接执行被拒绝任务的run方法，除非线程池已经shutdown，则直接抛弃任务。

 - `②AbortPolicy`

该策略下，直接丢弃任务，并抛出RejectedExecutionException异常。

 - `③DiscardPolicy`

该策略下，直接丢弃任务，什么都不做。

 - `④DiscardOldestPolicy`

该策略下，抛弃进入队列最早的那个任务，然后尝试把这次拒绝的任务放入队列
> 创建线程的方式

- 继承`Thread`
  - 重写 `run` 方法。
  - 然后创建这个子类对象，并调用 `start` 方法启动线程
- `Runnable` ，并实现 `run` 方法，也可以创建一个线程。
  - 首先定义一个类实现 `Runnable` 接口，并实现 `run` 方法。
  - 然后创建 `Runnable` 实现类对象，并把它作为 `target` 传入 `Thread` 的构造函数中
  - 最后调用 `start` 方法启动线程。
- 实现 `Callable` 接口，并结合 `Future` 实现
  - 首先定义一个 `Callable` 的实现类，并实现 `call` 方法。call 方法是带返回值的。
  - 然后通过 `FutureTask` 的构造方法，把这个 `Callable` 实现类传进去。
  - 把 `FutureTask` 作为 `Thread` 类的 `target` ，创建 `Thread` 线程对象。
  - 通过 `FutureTask` 的 `get`方法获取线程的执行结果。
- 通过线程池创建线程
  - 此处用 JDK 自带的 `Executors` 来创建线程池对象。
  - 首先，定一个 `Runnable` 的实现类，重写 `run` 方法。
  - 然后创建一个拥有固定线程数的线程池。
  - 最后通过 `ExecutorService` 对象的 `execute` 方法传入线程对象


> 线程之间的通信方式

1、`wait()`、`notify()`、`notifyAll()`

如果线程之间采用`synchronized`来保证线程安全，则可以利用`wait()`、`notify()`、`notifyAll()`来实现线程通信。这三个方法都不是Thread类中所声明的方法，而是`Object`类中声明的方法。原因是每个对象都拥有锁，所以让当前线程等待某个对象的锁，当然应该通过这个对象来操作。并且因为当前线程可能会等待多个线程的锁，如果通过线程来操作，就非常复杂了。另外，这三个方法都是本地方法，并且被`final`修饰，无法被重写。

`wait()`方法可以让当前线程释放对象锁并进入阻塞状态。`notify()`方法用于唤醒一个正在等待相应对象锁的线程，使其进入就绪队列，以便在当前线程释放锁后竞争锁，进而得到CPU的执行。`notifyAll()`用于唤醒所有正在等待相应对象锁的线程，使它们进入就绪队列，以便在当前线程释放锁后竞争锁，进而得到CPU的执行。

每个锁对象都有两个队列，一个是就绪队列，一个是阻塞队列。就绪队列存储了已就绪（将要竞争锁）的线程，阻塞队列存储了被阻塞的线程。当一个阻塞线程被唤醒后，才会进入就绪队列，进而等待CPU的调度。反之，当一个线程被wait后，就会进入阻塞队列，等待被唤醒。

2、`await()`、`signal()`、`signalAll()`

如果线程之间采用`Lock`来保证线程安全，则可以利用`await()`、`signal()`、`signalAll()`来实现线程通信。这三个方法都是`Condition`接口中的方法，该接口是在Java 1.5中出现的，它用来替代传统的wait+notify实现线程间的协作，它的使用依赖于 Lock。相比使用wait+notify，使用Condition的await+signal这种方式能够更加安全和高效地实现线程间协作。

Condition依赖于Lock接口，生成一个`Condition`的基本代码是`lock.newCondition()` 。 必须要注意的是，`Condition` 的 `await()/signal()/signalAll()` 使用都必须在`lock`保护之内，也就是说，必须在lock.lock()和lock.unlock之间才可以使用。事实上，`await()/signal()/signalAll()` 与 `wait()/notify()/notifyAll()`有着天然的对应关系。即：Conditon中的`await()`对应Object的`wait()`，Condition中的`signal()`对应Object的`notify()`，`Condition`中的`signalAll()`对应Object的`notifyAll()`。

3、`BlockingQueue`

Java 5提供了一个`BlockingQueue`接口，虽然`BlockingQueue`也是Queue的子接口，但它的主要用途并不是作为容器，而是作为线程通信的工具。`BlockingQueue`具有一个特征：当生产者线程试图向`BlockingQueue`中放入元素时，如果该队列已满，则该线程被阻塞；当消费者线程试图从`BlockingQueue`中取出元素时，如果该队列已空，则该线程被阻塞。

程序的两个线程通过交替向BlockingQueue中放入元素、取出元素，即可很好地控制线程的通信。线程之间需要通信，最经典的场景就是生产者与消费者模型，而BlockingQueue就是针对该模型提供的解决方案。

> 为什么不建议使用Executors类来创建线程池
exectors的牧人构造器会使用`LinkedBlockingQueue<Runnable>`误解阻塞队列来创建等待队列，若是有很多的任务就会添加到该队列中可能会出现oom内存不足的问题。

建议使用ThreadPoolExector构造方法来定义线程池，这样可以灵活控制 。

> 线程池的状态
- 1、Running 正常运行
- 2、shutdown正在关闭，但是线程池不会接受新任务但会把已有任务执行完，旧任务执行完中断
- 3、stop，shutdownnow 立马停掉 ，既不接受新任务，也不再执行就任务，旧任务直接中断
- 4、tidying 没有任务在运行后就是tidying状态会调用terminaled()方法 
- 5、terminated线程池执行玩terminalted方法之后就进入该状态  



### 多线程
>CountDownLatch和Semaphore的区别和底层原理
CountDownLatch表示一个计数器。一个线程调用countDwonLatch的await方法会被阻塞，到AQS队列中排队 其他线程可以调用counntDownLatch的countDown方法进行减一。
countDownlatch中的数字减一，数字减到0就将aqs队列中的线程一次唤醒。

Semaphore代表信号量。设置许可的数量，表示同时可以有多少个线程可以使用信号量。使用acquire()可以来获得信号量，没有许可就会被阻塞到AQS队列中，可以通过release来释放许可，有线程释放许后AQS中的正在排队的第一个线程开始一一唤醒，直到没有空闲许可。 


## jvm
### 垃圾回收算法
> 垃圾回收算法

GC 把程序不用的内存空间视为「垃圾」，（几乎所有的）GC 要做的就只有两件事：

找到内存空间里的垃圾，使其和活对象分开来。
回收垃圾对象的内存，使得程序可以重复使用这些内存。

- 基于可达性分析的 GC
  - 基本思路就是通过根集合（gc root）作为起始点，从这些节点出发，根据引用关系开始搜索，所经过的路径称为引用链，当一个对象没有被任何引用链访问到时，则证明此对象是不活跃的，可以被回收。使用此类算法的有JVM、.NET、Golang等。
  -  垃圾回收的效率较高，实现起来比较简单
  -  缺点在于 GC 期间，整个应用需要被挂起（`STW`，`Stop-the-world`，下同），后面很多此类算法的提出，都是在解决这个问题（缩小 `STW` 时间）。
- 基于引用计数法的 GC
  - 在堆内存中分配对象时，会为对象分配一段额外的空间，这个空间用于维护一个计数器，如果有一个新的引用指向这个对象，则计数器的值加1；如果指向该对象的引用被置空或指向其它对象，则计数器的值减1。每次有一个新的引用指向这个对象时，计数器加1；反之，如果指向该对象的引用被置空或指向其它对象，则计数器减1；当计数器的值为0时，则自动删除这个对象。使用此类算法的有 `Python`、`Objective-C`、`Perl`等。
  - 引用计算法是是算法简单，实现较难
  - 天然带有增量特性（incremental），GC 可与应用交替运行，不需要暂停应用；同时，在引用计数法中，每个对象始终都知道自己的被引用数，当计数器为0时，对象可以马上回收，而在可达性分析类 GC 中，即使对象变成了垃圾，程序也无法立刻感知，直到 GC 执行前，始终都会有一部分内存空间被垃圾占用
  - 引用计数算法无法解决「**循环引用无法回收**」的问题，即两个对象互相引用，所以各对象的计数器的值都是 1，即使这些对象都成了垃圾（无外部引用），GC 也无法将它们回收
  - 引用计数算法最大的问题在于：计数器值的增减处理非常繁重，譬如对根对象的引用
  - 多个线程之间共享对象时需要对计数器进行原子递增/递减，这本身又带来了一系列新的复杂性和问题，计数器对应用程序的整体运行速度的影响

真正的工业级实现一般是这两类算法的组合

- 串行执行：垃圾回收器执行的时候应用程序挂起，串行执行指的是垃圾回收器有且仅有一个后台线程执行垃圾对象的识别和回收；
- 并行执行：垃圾回收器执行的时候应用程序挂起，但是在暂停期间会有多个线程进行识别和回收，可以减少垃圾回收时间；
- 并发执行：垃圾回收器执行期间，应用程序不用挂起正常运行（当然在某些必要的情况下垃圾回收器还是需要挂起的）

#### 三色标记算法

>三色标记算法

背后的首要原则就是把堆中的对象根据它们的颜色分到不同集合里面，这三种颜色和所包含的意思分别如下所示：

- 白色：还未被垃圾回收器标记的对象
- 灰色：自身已经被标记，但其拥有的成员变量还未被标记
- 黑色：自身已经被标记，且对象本身所有的成员变量也已经被标记'


在 GC 开始阶段，刚开始所有的对象都是白色的，在通过可达性分析时，首先会从根节点开始遍历，将 GC Roots 直接引用到的对象 A、B、C 直接加入灰色集合，然后从灰色集合中取出 A，将 A 的所有引用加入灰色集合，同时把 A 本身加入黑色集合。最后灰色集合为空，意味着可达性分析结束，仍在白色集合的对象即为 GC Roots 不可达，可以进行回收了

在标记对象是否存活的过程中，对象间的引用关系是不能改变的，这对于串行 GC 来说是可行的，因为此时应用程序处于 STW 状态。对于并发 GC 来说，在分析对象引用关系期间，对象间引用关系的建立和销毁是肯定存在的，如果没有其他补偿手段，并发标记期间就可能出现对象多标和漏标的情况

多标不会影响程序的正确性，只会推迟垃圾回收的时机，漏标会影响程序的正确性，需要引入读写屏障来解决漏标的问题


#### 读屏障（Read barrier）和写屏障（Write barrier）

指的是程序在从堆中读取引用或更新堆中引用时，GC 需要执行一些额外操作，其本质是一些同步的指令操作，在进行读/写引用时，会额外执行这些指令。

读/写屏障实现的是「对 *读/写* 引用这个操作的环切」，即该操作前后都在屏障的范畴内，可以将读/写屏障类比于 Spirng 框架里的拦截器。下面所示的代码，当从 foo 的成员变量第一次从堆上被加载时，就会触发读屏障（后续使用该引用不会触发 ），而当 bar 的成员变量(引用类型的)被分配/写入时，会触发写屏障


方法一：

开启写屏障，当新增引用关系后，触发写屏障，发出引用的黑色或者白色对象会被标记成灰色（例子中 A 将被标记为灰色并进入灰色集合），或者将被引用对象标记为灰色。
开启读屏障，当检测到应用即将要访问白色对象时，触发读屏障，GC 会立刻访问该对象并将之标为灰色。这种方法被称为「增量更新（Increment Update）」。

方法二：

开启写屏障。当删除引用关系前，将所有即将被删除的引用关系的旧引用记录下来（C -> E），最后以这些旧引用为根重新扫描一遍，这种方法实际上是「SATB（Snapshot At The Begining） 算法」



JVM 里还有另外一组内存屏障的概念：读屏障（Load Barrier）和写屏障（Store Barrier），这两组指令和上面我们谈及的屏障不同，Load Barrier 和 Store Barrier主要用来保证主缓存数据的一致性以及屏障两侧的指令不被重排序
#### 基础垃圾回收算法
- 标记-清除算法
  - 标记阶段和清除阶段构成。标记阶段是把所有活动对象都做上标记的阶段，有*对象头标记*和*位图标记*（`bitmap marking`）这两种方式，后者可以与写时复制技术（`copy-on-write`）相兼容。清除阶段是把那些没有标记的对象，也就是非活动对象回收的阶段，回收时会把对象作为分块，连接到被称为「空闲链表（`free-lis`）」的链表中去。
  - 清除操作并不总是在标记阶段结束后就全部完成的，一种「延迟清除（`Lazy Sweep`）」的算法可以缩减因清除操作导致的应用 `STW` 时间。延迟清除算法不是一下遍历整个堆（清除所花费的时间与堆大小成正比），它只在分配对象时执行必要的堆遍历，同时其算法复杂度只与活动对象集的大小成正比
- 标记-压缩算法
  - 清除算法的基础上，用「压缩」取代了「清除」这个回收过程， GC 将已标记并处于活动状态的对象移动到了内存区域的起始端，然后清理掉了端边界之外的内存空间-清除算法的基础上，用「压缩」取代了「清除」这个回收过程， GC 将已标记并处于活动状态的对象移动到了内存区域的起始端，然后清理掉了端边界之外的内存空间
- 标记-复制算法
  - 标记-复制算法与标记-压缩算法非常相似，因为它们会对活动对象重新分配（reloacate）空间位置。两个算法区别是：在标记-复制算法中，reloacate 目标是一个不同的内存区域。


#### 垃圾回收算法的改进

三种垃圾回收算法，会针对基础算法中诸如堆碎片化、暂停时间过长、空间利用率不高等不足进行改进

##### 分代算法（Generational GC）

分代算法对基础算法的改进主要体现在该算法减小了 GC 的作用范围。如前所述，标记过程和对象的 reloacate 过程都需要完全停止应用程序进行堆搜索，堆空间越大，进行垃圾回收所需的时间就越长，如果 GC 的堆空间变小，应用暂停时间也会相应地降低

代算法把对象分类成几代，针对不同的代使用不同的 GC 算法

综合来看，代数划分为 2 代或者 3 代是最好的。

在经过新生代 GC 而晋升的对象把老年代空间填满之前，老年代 GC 都不会被执行。因此，老年代 GC 的执行频率要比新生代 GC 低。通过使用分代垃圾回收，可以改善 GC 所花费的时间（吞吐量）

> 分代算法有着哪些问题

1、不同分代在堆空间之间应当如何划分
有的把老年代的最后一个代通过标记-复制算法处理（Lisp Machine），还有的算法会把最后一个代通过标记-压缩算法回收，降低复制算法出现的频繁换页的问题。

2、如何标记代际之间的引用关系
解决引用问题的关键是引入写屏障：如果一个老年代的引用指向了一个新生代的对象，就会触发写屏障

在写入屏障里，首先会判断：

- 发出引用的对象是不是老年代对象；
- 目标引用标对象是不是新生代对象；
- 发出引用的对象是否还没有加入记录集

> 老年代不用标记-复制算法

老年代一般是难以消亡的，而标记清除算法在对象存活率比较高的情况下就需要进行较多的复制操作，效率将会降低，所以在老年代一般不能选择这种算法。

> 新生代为什么分为Eden和Survivor，他们的比例是多少

新生代分为一个Eden和两个Survivor区。大小比例未8：1：1。

新产生的对象归到新生代的Eden区域中，

新生代的gc多采用标记复制算法。分为两个区域，每次将还活着的对象复制到另一块内存中去，完全清除掉另一块内存空间。运行简单且高效。但是比较浪费空间
。实际上90%的新生代对象熬不过第一次gc。因此在发生垃圾回收时，将Eden和survivor中未被清除掉的对象复制到另一块survivor中，既节省了空间又提高了效率。

> 为什么设置两个survivor区域

浪费的空间只占10%，两个survivor区域可以解决内存碎片化。

> G1垃圾收集器

G1 garbage first面向服务端的垃圾收集器。遵循分代收集理论设计的。但是也是基于区域的理念。将内存分为大小相同的region。每个region分别扮演survivor，eden和老生代区域。g1还将一半region区域大小的对象看作是大对象，一个redion大小以上的对象看作是超大对象，会被连续存放在Humongous Redion中 ，g1会将大对象当作是老年代来看待.每次gc都以一阵个region为单位回收，避免在整个java队中进行垃圾回收。g1维护一个优先级队列，每次在规定收集时间内有限回收收益最大的region。

> cms垃圾处理器

Cms concurrent mark sweep 基于标记清除算法的。追求最短的回收停顿时间
- 初始标记
  - 标记gc root能直接关联到的对象引用
- 并发标记
  - 和当前线程并发执行，标记并发执行前该线程的初始标记之后能关联到的对象
- 重新标记
  - 标记在并发执行中，线程继续运作导致标记记录有所变化的那一部分对象的标记记录，执行时间比初始标记长的那笔并发标记短。
- 并发清除
  - 和当前线程一起并发执行删除清理掉当前已经死亡的对象。

并发执行降低原线程的执行速度和吞吐量。

会产生大量的内存碎片，导致stop the world的full gc的运行


##### 增量算法(Incremental GC）
改进主要体现在该算法通过并发的方式，降低了 STW 的时间。

增量算法的核心思想是：通过 GC 和应用程序交替执行的方式，来控制应用程序的最大暂停时间。

增量算法的「增量」部分，主要有「增量更新（Incremental Update）」和「增量拷贝（Incremental Copying）」两种，前者主要是做「标记」增量，后者是在做「复制」增量。

漏标问题通过写屏障来实现

增量算法中大量使用了读写屏障（主要是写屏障），给应用程序带来了负担，结果就是 GC 的吞吐相较于其他的算法来说不高。
##### 并发算法（Concurrent GC）
广义上的并发算法指的是在 GC 过程中存在并发阶段的算法，如 G1 中存在并发标记阶段，可将其整个算法视为并发算法。

狭义上的并发垃圾回收算法是以基础的标记-复制算法为基础，在各个阶段增加了并发操作实现的。与复制算法的3个阶段相对应，分为并发标记（mark）、并发转移（relocate）和并发重定位（remap）

1）并发标记

从 GC Roots 出发，使用遍历算法对对象的成员变量进行标记。同样的，并发标记也需要解决标记过程中引用关系变化导致的漏标记问题，这一点通过写屏障实现；

（2）并发转移

根据并发标记后的结果生成转移集合，把活跃对象转移（复制）到新的内存上，原来的内存空间可以回收，转移过程中会涉及到应用线程访问待转移对象的情况，一般的解决思路是加上读屏障，在完成转移任务后，再访问对象；

（3）并发重定位

对象转移后其内存地址发生了变化，所有指向对象老地址的指针都要修正到新的地址上，这一步一般通过读屏障来实现。


### jvm 运行java的阶段
> 类加载的过程

- 加载
  - 通过全类名获取类的二进制字节流
  - 将类的静态存储结构加载为方法区的可运行数据结构
  - 内存中生成类的一个Class对象作为方法区该类的信息和结构的入口
- 连接
  - 验证
    - 文件格式验证，元数据验证，字节码验证和符号引用验证
    - 校验数据是否符合jvm的规范，是否有未加载的引用等
  - 准备
    - 将类的静态数据等分配内存并初始化零值
  - 解析
    - jvm将常量池中的符号引用替换为直接引用
- 初始化
  - 为java类中的变量赋予clinit方法即程序员规定的初始化值
- 使用
- 卸载

> 对象实例化的过程

使用字节码中的`init`方法进行初始化

- 先静态，后非静态
- 先父类,后子类 
- 先变量，后代码块
- 先代码块，后构造方法

 
父类静态变量->父类静态代码块->子类静态变量->子类静态代码块->父类变量->父类代码块->父类构造方法->子类变量->子类代码块->子类构造方法

>元空间

在栈外，元空间占用的是本地内存。

> jvm的类加载模型 以及 双亲委派模式

区别不同的类的前提是同一个类加载器加载的类，不同加载器加载的类注定是不同的。

类加载器有 启动类加载器->扩展类加载器->应用程序类加载器->自定义类加载器


启动类加载器加载`JAVA_HOME/lib`目录下的类

扩展类加载器加载的是`\lib\ext`目录之下的。这是一种类似于java库的扩展装置。

应用程序类加载器默认加载的是用户路径下的加载器，别名系统类加载器

双亲委派机制
记载器虽是继承关系但实际上的使用是组合关系。

有个加载器开始加载程序时，需要先判断是否加载过，然后未加载过的类使用父类的加载器进行加载，保证如Object等类在各个类加载环境下都是一致的。没有自定义加载器的化默认使用应用程序类加载器。

### 排查jvm的问题
- 正常运行的系统
  - jmap查看jvm各个区域的使用情况
  - jstack查看jvm线程的运行情况
  - jstat查看垃圾回收情况，特别是fullgc
  - jvisualvm等工具来进行分析
  - 猜测频繁gc的原因，频繁gc又没有发生oom的情况，表示fullgc回收了太多的对象了，折线对象最好是在younggc的时候回收掉，，尝试加大年轻代的大小
  - 找到占用cpu多的线程，定位具体方法，优化运行
- 发生oom的系统
  - C-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/base
  - 我们可以利用jsisualvm等工具来分析dump文件
  - 根据dump文件找到异常的实例对象，和异常的线程（占用CPU高），定位到具体的代码

> jvm启动时设置的参数

- 标注指令： -开头，这些是所有的HotSpot都支持的参数。可以用java -help 打印出来。
- 非标准指令： -X开头，这些指令通常是跟特定的HotSpot版本对应的。可以用java -X 打印出来。
- 不稳定参数： -XX 开头，这一类参数是跟特定HotSpot版本对应的，并且变化非常大。
## 内存
> 内存溢出和内存泄漏

- 内存溢出：需要的内存超出系统所能够提供的内存且无法再次申请到足够的内存空间
  - 原因
    - 内存中加载的数据来过于庞大
    - 集合中有对对象的引用，使用完后没有清空
    - 代码中存在死循环，产生大量的重复的对象实体
    - 运行之前jvm申请的内存空间太小
    - 第三方软件的bug
  - 建议
    - 程序运行前jvm申请较大的内存空间，修改启动参数申请更大内存
    - 查看错误日志，查看oomError错误之前是否还有其他的异常或者错误
    - 对代码进行排除和分析，找出内存溢出的位置并解决
    - 使用内存查看工具动态查看内存的使用情况。
- 内存泄漏： 程序运行过程中产生的临时变量没有被GC回收，始终占用着内存，内存既不能够被使用也不能够分配给其他程序就发生了内存泄露
  - 内存泄漏的主要原因是长生命周期的对象持有短周期对象的引用
  - 类型
    - 常发性内存泄漏--多次执行内存泄漏的代码
    - 偶发式内存泄漏--特定环境和特定操作下才会产生
    - 一次性内存泄漏--只发生一次
    - 隐式内存泄漏--不及时释放内存，到最后才释放内存可能会耗尽机器的所有内存
  - 建议
    - 今早释放无用对象的引用
    - 少使用静态类型
    - 字符串的处理少使用String多使用StringBuilder或者StringBuffer
    - 避免在循环中创建对象

> 那些区域会发生oomError

除了程序计数器区域外的其他jvm内存区域都有产生oom异常的可能

- java堆溢出
- 方法区溢出
  - 在运行生成大量动态类的时候就会发生内存泄漏。程序可以使用GGlib字节码增强或者动态语言，或者jsp（jsp会编译成为java的一个类）
- 虚拟运行栈 和 本地方法栈
  - 允许动态扩展，当申请不到足够的内存的时候就会发生内存溢出
- 本地直接内存溢出

# 框架

## Spring
> spring 和SpringBoot的区别

spring是一系列java开发的基础框架。包含很多基础的部分比如spring aop,spring orm,spring test,spring mvc,spring security等。简化了java项目的开发。

springboot是spring框架的扩展。消除了设置spring框架的xml的配置，可以更快更高效的开发程序。

spring boot能独立开发spring框架应用。
能够通过starter快速高效的配置
嵌入式tomcat，jetty容器
尽可能的自动配置spring应用


> 简述一下自动装配

自动装配就是通过注解或者一些简单的配置在springboot的帮助下实现某下功能。

`@SpringBootApplication`注解包含有三个注解

- `@Configuration` 允许在上下文中注册额外的bean或者其他的配置类
- `@EnableAutoConfiguration` 启用springboot的自动配置注解
- `@ComponentScan` 规定springboot可以扫描的包，也可以不扫描的包

1、首先是判断`spring.boot.enableautoconfiguation=true` spring boot的自动装配是否开启
2、根据`@ComponentScan`扫描出所有引入的依赖之下的`META_INF/spring.factories`下的所有配置类。
3、根据注解`@ConditionOnXXX`注解判断是否满足条件。将满足条件的bean注入到容器中。


>拦截器和过滤器的区别

过滤器`filter`

拦截器 `interceptor`

过滤器（`Filter`）
过滤器，是在`java web`中将你传入的`request`、`response`提前过滤掉一些信息，或者提前设置一些参数。然后再传入Servlet或Struts2的 action进行业务逻辑处理。比如过滤掉非法url（不是login.do的地址请求，如果用户没有登陆都过滤掉），或者在传入Servlet或Struts2的action前统一设置字符集，或者去除掉一些非法字符。

拦截器（`Interceptor`）
拦截器，是面向切面编程（`AOP`，Aspect Oriented Program）的。就是在你的Service或者一个方法前调用一个方法，或者在方法后调用一个方法。比如动态代理就是拦截器的简单实现，在你调用方法前打印出字符串（或者做其它业务逻辑的操作），也可以在你调用方法后打印出字符串，甚至在你抛出异常的时候做业务逻辑的操作。

通俗理解：
- （1）过滤器（`Filter`）：当你有一堆东西的时候，你只希
- 望选择符合你要求的某一些东西。定义这些要求的工具，就是过滤器。（理解：就是一堆字母中取一个B）
- （2）拦截器（`Interceptor`）：在一个流程正在进行的时候，你希望干预它的进展，甚至终止它进行，这是拦截器做的事情。（理解：就是一堆字母中，干预它，通过验证的少点，顺便干点别的东西）

二、拦截器与过滤器的区别
区别：
- ①：拦截器是基于java的反射机制的，而过滤器是基于函数的回调。
- ②：拦截器不依赖于servlet容器，而过滤器依赖于servlet容器。
- ③：拦截器只对action请求起作用，而过滤器则可以对几乎所有的请求起作用。
- ④：拦截器可以访问action上下文、值、栈里面的对象，而过滤器不可以。
- ⑤：在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。
<!-- - ⑥：拦截器可以获取IOC容器中的各个bean，而过滤器不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。 -->

三、拦截器与过滤器的触发时机

拦截器与过滤器触发时机不一样

过滤器是在请求进入容器后，但请求进入servlet之前进行预处理的。请求结束返回也是，是在servlet处理完后，返回给前端之前。

过滤器包裹servlet，servlet包裹住拦截器

四、使用场景

SpringMVC的处理器拦截器类似于Servlet开发中的过滤器Filter，用于对处理器进行预处理和后处理。

- 1、日志记录：记录请求信息的日志，以便进行信息监控、信息统计、计算PV（Page View）等。
- 2、能权限检查：如登录检测，进入处理器检测检测是否登录，如果没有直接返回到登录页面；
- 3、性监控：有时候系统在某段时间莫名其妙的慢，可以通过拦截器在进入处理器之前记录开始时间，在处理完后记录结束时间，从而得到该请求的处理时间（如果有反向代理，如apache可以自动记录）；
- 4、通用行为：读取cookie得到用户信息并将用户对象放入请求，从而方便后续流程使用，还有如提取Locale、Theme信息等，只要是多个处理器都需要的即可使用拦截器实现。
- 5、OpenSessionInView：如hibernate，在进入处理器打开Session，在完成后关闭Session。


> 多级缓存架构设计

三级缓存思路 nginx，redis，jvm本地缓存

时效性高的数据信息，采取数据库和redis双写的方式

时效性低的数据，采取MQ异步通知的方式，数据生产服务，异步拉取服务的数据，更新tomcat，jvm，redis的数据

nginx->redis->tomcat+jvm->数据库

nginx 针对高热点的高并发访问

redis 针对较高热点，大规模的离散访问

jvm堆内缓存保证缓存雪崩时减少数据库直接承受的压力.

> spring使用到的设计模式
单例模式，构建器模式， 适配器模式， 访问者模式，观察者模式，代理模式，策略模式，模板方法模式，责任链模式。
### 启动过程
1. 扫描得到所有的BeanDefinition对象，并存入一个Map中。
2. 筛选出非懒记载的单例bean进行创建bean
3. 利用BeanDefinition创建Bean，bean的启动过程
4. 创建完bean之后spring会发布一个容器启动事件。
### bean
> bean的生命周期

创建、初始化、调用和销毁

1. 推断构造方法
2. 实例化
3. 填充属性，依赖注入
4. 处理Aware回调
5. 初始化前处理PostConstruct注解
6. 初始化处理InitiallingBean接口
7. 初始化后进行aop


`@PostConstruct`在SetBeanFactory方法之后调用

`PreDestroy`在spring容器注销之前调用这个方法。

>spring 是如何解决循环依赖的

循环依赖主要分为三种
- 构造器循环依赖，无法处理
- 单例setter循环依赖，spring解决
- 非单例的setter循环依赖，无法处理

spring通过***三级缓存***来解决单例setter的循环依赖的。

单例对象的初始化大体分为三步
- createBeanInstance实例化，构造方法实例化对象
- populateBean填充属性，填充属性，多bean的依赖属性进行填充
- intializeBean调用xml的init方法
  
三级缓存
- singletonFactories 进入实例化阶段的单例对象工厂的cache 三级缓存
- earlySingletonObjects 完成实例化但是尚未初始化的，提前曝光的单例对象的cache 二级缓存
- singletonObjects 完成初始化的单例对象的cache 一级缓存

循环依赖主要分为第一二部。假设a和b的单例setter循环依赖。

首先初始化a，使用a的构造器实例化a，之后通过setter方法实例化a，发现a在获取getB的时候，b还没有实例，此时将a放到三级缓存singletonFactories中，走create流程，b在初始化的时候发现自己依赖了a，于是去一级缓存张寻找，知道找到三级缓存找到a，拿到后顺利完成初始化阶段，将实例对象放入一级缓存中，a初始化也能够再次拿到b对象。


>@Autowired和@Resource注解都有什么区别

- autowired时spring的注解，resource是jdk的注解
- autowired按照类型注入，想使用按照名字注入可以配合@qualifier一起使用。resource可以和默认按照name注入，也可以按照类型注入
- autowired 的require=true的话，可以允许null值。resource若是没有指定，先按照neme，没有注入的话再按照类型

> spring的单例bean是线程安全的吗

spring没有对bean提出线程安全的策略，但是若是bean是一个无状态的bean，线程的操作不会对成员进行除了查询之的操作那么bean是线程安全的例如controller，service，dao等。如果是有状态的bean，可以使用ThreadLocal做数据隔离，保证线程安全。

### aop
> 对spring aop的理解

aop面向切面编程，是一种编程思想，是对面向对象编程oop的一种补充。aop将程序抽象成各种切面。切面，在应用对当中的横切点，可以将其封装成为单独的模块

- 连接点，join point 被拦截的对象
- 切点 point cut适配不同的连接点所执行的方法
- 通知，约定流程下的方法 前置通知，后置通知，异常通知，环绕通知
- 目标对象 被代理的对象
- 引入 引入其他新的类和方法来增强现有类和方法
- 织入 通过动态代理技术，通过生成代理对象来拦截连接点，并将各类通知织入约定流程的过程
- 切面 定义各种切点，通知引入的内容

> aop的实现方式

- jdk动态代理。java提供的动态代理技术，运行时创建接口的代理实例，spring aop默认采用这种方法，在接口的代理实例织入代码
- CGlib动态代理。采用底层的字节码技术，生成被代理类的子类实例，当目标对象不存在接口时候，采用这种方式

实现日志功能，事务管理

性能方面，cglib的比jdk动态代理的要高很多，但是cglib创建实例比jdk动态代理的开销的要高很多

因此单例模式下使用cglib的较多，多例模式下，使用jdk动态代理比较好 


> aop不能对那些类进行增强

springaop只能对ioc容器中的bean进行增强。

CGLib对final修饰的类不能进行代理

### 事务
> spring如何管理事务

spring为事务管理提供了统一的编程模板，在高层次上建立了统一的事务抽象。无论使用mybatis，hibernate、jpa还是jdbc。spring都可以让用户以统一的编程模型进行事务管理

- 1、编程式事务
  - spring 提供了`TransactionTemplate`模板，可以通过编程的方式实现事务管理，而无需关注资源获取、复用、释放、事务同步及异常处理等操作。相对于声明式事务来说，这种方式相对麻烦一些，但是好在更为灵活，我们可以将事务管理的范围控制的更为精确
- 2、声明式事务
  - Spring事务管理的亮点在于声明式事务管理，它允许我们通过声明的方式，在IoC配置中指定事务的边界和事务属性，Spring会自动在指定的事务边界上应用事务属性。相对于编程式事务来说，这种方式十分的方便，只需要在需要做事务管理的方法上，增加`@Transactional`注解，以声明事务特征即可。

> spring的事务传播方式

事务传播 一个业务方法调用其他业务方法的时候，两个业务方法都是要保证事务的。事务传播机制就是控制当前事务如何传播到被嵌套使用的业务方法中。

|事务传播类型|说明|
|----|----|
|PROPAGATION_REQUIRED	|如果当前没有事务，则新建一个事务；如果已存在一个事务，则加入到这个事务中。这是最常见的选择。|
|PROPAGATION_SUPPORTS|	支持当前事务，如果当前没有事务，则以非事务方式执行。|
|PROPAGATION_MANDATORY|使用当前的事务，如果当前没有事务，则抛出异常。|
|PROPAGATION_REQUIRES_NEW|新建事务，如果当前存在事务，则把当前事务挂起。|
|PROPAGATION_NOT_SUPPORTED|以非事务方式执行操作，如果当前存在事务，则把当前事务挂起。|
|PROPAGATION_NEVER|以非事务方式执行操作，如果当前存在事务，则抛出异常。|
|PROPAGATION_NESTED|如果当前存在事务，则在嵌套事务内执行；如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作|

>spring的事务如何配置

事务的打开、回滚和提交是由事务管理器来完成的，我们使用不同的数据库访问框架，就要使用与之对应的事务管理器。在Spring Boot中，当你添加了数据库访问框架的起步依赖时，它就会进行自动配置，即自动实例化正确的事务管理器。

对于声明式事务，是使用@Transactional进行标注的。这个注解可以标注在类或者方法上。

当它标注在类上时，代表这个类所有公共（public）非静态的方法都将启用事务功能。

当它标注在方法上时，代表这个方法将启用事务功能。

另外，在@Transactional注解上，我们可以使用isolation属性声明事务的隔离级别，使用propagation属性声明事务的传播机制。

> Spring的事务什么时候会失效

- 方法内的自调用：Spring事务是基于AOP的，只要使用代理对象调用某个方法时，Spring事务才能生效，而在一个方法中调用使用this.xxx()调用方法时，this并不是代理对象，所以会导致事务失效。
  - 解决发法
    - 1：把调用方法拆分到另外一个Bean中
    - 2：自己注入自己
    - 3：解决办法3：`AopContext.currentProxy()+@EnableAspectJAutoProxy(exposeProxy = true)`
- 方法是private的：Spring事务会基于CGLIB来进行AOP，而CGLIB会基于父子类来失效，子类是代理类，父类是被代理类，如果父类中的某个方法是private的，那么子类就没有办法重写它，也就没有办法额外增加Spring事务的逻辑。
- 方法是final的：原因和private是一样的，也是由于子类不能重写父类中的final的方法
- 单独的线程调用方法：当Mybatis或JdbcTemplate执行SQL时，会从ThreadLocal中去获取数据库连接对象，如果开启事务的线程和执行SQL的线程是同一个，那么就能拿到数据库连接对象，如果不是同一个线程，那就拿到不到数据库连接对象，这样，Mybatis或JdbcTemplate就会自己去新建一个数据库连接用来执行SQL，此数据库连接的autocommit为true，那么执行完SQL就会提交，后续再抛异常也就不能再回滚之前已经提交了的SQL了。
- 没加`@Configuration`注解：如果用SpringBoot基本没有这个问题，但是如果用的Spring，那么可能会有这个问题，这个问题的原因其实也是由于Mybatis或JdbcTemplate会从ThreadLocal中去获取数据库连接，但是ThreadLocal中存储的是一个MAP，MAP的key为DataSource对象，value为连接对象，而如果我们没有在AppConfig上添加@Configuration注解的话，会导致MAP中存的DataSource对象和Mybatis和JdbcTemplate中的DataSource对象不相等，从而也拿不到数据库连接，导致自己去创建数据库连接了。
- 异常被吃掉：如果Spring事务没有捕获到异常，那么也就不会回滚了，默认情况下Spring会捕获RuntimeException和Error。
- 类没有被Spring管理
- 数据库不支持事务

> Spring是如何实现事务的

1. sping的事务是基于数据库的事务和spring的aop机制实现的。
2. 加了`@Transactional`注解的Bean，Spring会创建一个代理对象作为Bean。
3. 当调用bean的方法的时候，回先判断该方法方法上是否添加了`@Transactional`注解，若是添加了该注解，就会利用事务管理器创建一个数据库连接。
4. 并且修改数据库连接的`autoCommit`为false，禁止自动提交。
5. 执行当前方法，会执行sql
6. 执行完当前方法后没有异常就提交事务
7. 捕捉到异常且需要回滚的话就回滚事务
8. spring的事务隔离级别就是数据库的隔离级别
9. spring的事务传播机制就是spring自己实现的
10. spring的事务传播机制是基于数据库连接来实现的，一个数据库连接对应一个事务，，若是需要新开一个事务就是需要一个新的数据库连接，在此基础上执行sql语句
    

### BeanFactory
>BeanFactory的和ApplicationContext的区别
BeanFactory是Spring中非常核心的组件，表示Bean工厂，可以生成Bean，维护Bean，而ApplicationContext继承了BeanFactory，所以ApplicationContext拥有BeanFactory所有的特点，也是一个Bean工厂，但是ApplicationContext除开继承了BeanFactory之外，还继承了诸如EnvironmentCapable、MessageSource、ApplicationEventPublisher等接口，从而ApplicationContext还有获取系统环境变量、国际化、事件发布等功能，这是BeanFactory所不具备的

## SpringMVC
>怎么去做请求拦截
对controller进行拦截则可以使用springmvc的拦截器

对所有的请求进行拦截，包括静态资源则可以使用过滤器Filter

对controller之外的其他的bean进行拦截可以使用spring aop


## spring boot
> 原理

Spring Boot的原理利用Spring 的ioc容器。

SpringApplication.run放啊传入的启动类实际上是一种配置类，加载上面的注解，`@ComponentScan`会引导spring加载该配置类包下的所有@Bean或者@Responsity等类型注入的bean注入到容器中。或者是其他SpringMVC规定的可以代表bean的注解例如@service,
@Controller等。`@SpringBootApplication`注解包括`@EnableAutoConfiguration`注解，表示开启自动配置。`@import(xxAutoConfigure.class)` 可以手动导入自动配置类。自动配置类里面包含有很多的可以注入容器的Bean，可以根据情况注入到容器中。判断容器种是否安祖该条件二悬念则是否注入。很多SPringBoot的自动配置包都含有自动配置类。开始Springboot先寻找读取每个jar包下的spring.factories文件种规定的自动配置类生成一个大的HashMap，遍历每个自动配置类根据条件注入相应的bean。

自动配置的类过多，判断条件比较多，springboot会进行一些优化。比如在多cpu条件下会开启多线程处理条件判断加载，spring.factories文件中写有该类自动配置所需要的bean或者class


spring.factories文件的生成和lombok的底层比较类似


springboot3在编译的时候SpringBootApplicationAotProcessor.java已经扫描了包，bean已经生成了.java文件，启动之后直接注册到容器中就可以。


## Spring Cloud
>Spring Cloud有哪些常用组件，作用是什么？

- Eureka：注册中心
- Nacos：注册中心、配置中心
- Consul：注册中心、配置中心
- Spring Cloud Config：配置中心
- Feign/OpenFeign：RPC调用
- Kong：服务网关
- Zuul：服务网关
- Spring Cloud Gateway：服务网关
- Ribbon：负载均衡
- Spring CLoud Sleuth：链路追踪
- Zipkin：链路追踪
- Seata：分布式事务
- Dubbo：RPC调用
- Sentinel：服务熔断
- Hystrix：服务熔断

## MyBatis
> mybatis和jpa的区别

1、ORM映射关系不同
mybatis是数据库与结果集的映射，jpa（默认采用hibernate实现）是数据库和对象的映射
2、可移植性不同
jpa通过强大的结构和hql语言大大降低了对象和数据库之间的耦合度。
mybatis由于需要写sql，耦合度取决于书写的SQL水平。若sql不具备通用性而有很多数据库的特点的适合，mybatis的移植成本高于jpa
3、日志系统的完整性不同
jpa的日志强大，包括sql记录，异常警告，关系异常，优化警告，缓存提示脏数据警告等。
mybatis日志只有基本的记录功能
4、sql优化上的不同
mybatis的优化写在xml中，优化更方便。jpa生成了hql语句，无法直接进行维护，遇到复杂的报表等需求的时候无能为力，Hql有局限性。jpa虽然也支持原生sql，但是需要转换思维，开发不方便。

>mybatis支持输入输出的类型

简单类型、map类型、bean类型

> mybatis的#和$有什么不同

使用#设置参数的时候，mybatis会预先编译sql语句，在执行sql的时候，mybatis会为预编译的sql中的占位符？赋值，预编译也会防止sql注入，#号字符串变量会默认带着""

使用$的时候，会创建普通的sql语句，将参数直接拼接到sql中，效率安全性都不如前者，但是在特地给情境下有用。

> mybatis的分页
本质是个拦截器，对sql进行拦截，在sql上面加上limit等限制，效率不如自己写的分页sql，更灵活更高效

> Mybatis的缓存机制
mybatis的缓存分为一级缓存和二级缓存

一级缓存默认开启且无法关闭，一级缓存存在于sqlsession的生命周期内。在同一个sqlsession中查询，mybatis会把执行的方法和参数通过算法生成缓存的键值。将键值和缓存存入到一个map对象中。如果同一个sqlsession中有相同的方法和参数那么算法会生成相同的键值，可以返回已经缓存的对象

二级缓存存在于SqlSessionFactory的生命周期中。开启需要配置，在mybatis的全局配置中，setting中有个cacheEnabled，默认值为true，开启状态。在mapper.xml中开启  `<cache/>`

二级缓存的效果

- 映射语句文件中的所有SELECT 语句将会被缓存。
- 映射语句文件中的所有时INSERT 、UPDATE 、DELETE 语句会刷新缓存。
- 缓存会使用Least Recently Used ( LRU ，最近最少使用的）算法来收回。
- 根据时间表（如no Flush Interval ，没有刷新间隔），缓存不会以任何时间顺序来刷新。
- 缓存会存储集合或对象（无论查询方法返回什么类型的值）的 1024 个引用。
- 缓存会被视为read/write（可读／可写）的，意味着对象检索不是共享的，而且可以安全地被调用者修改，而不干扰其他调用者或线程所做的潜在修改。

## 其他
### session
> 5.1 cookie和session的区别是什么？
- 存储位置不同：cookie存放于客户端；session存放于服务端。
- 存储容量不同：单个cookie保存的数据<=4KB，一个站点最多保存20个cookie；而session并没有上限。
- 存储方式不同：cookie只能保存ASCII字符串，并需要通过编码当时存储为Unicode字符或者二进制数据；session中能够存储任何类型的数据，例如字符串、整数、集合等。
- 隐私策略不同：cookie对客户端是可见的，别有用心的人可以分析存放在本地的cookie并进行cookie欺骗，所以它是不安全的；session存储在服务器上，对客户端是透明的，不存在敏感信息泄露的风险。
- 生命周期不同：可以通过设置cookie的属性，达到cookie长期有效的效果；session依赖于名为JSESSIONID的cookie，而该cookie的默认过期时间为-1，只需关闭窗口该session就会失效，因此session不能长期有效。
- 服务器压力不同：cookie保存在客户端，不占用服务器资源；session保管在服务器上，每个用户都会产生一个session，如果并发量大的话，则会消耗大量的服务器内存。
- 浏览器支持不同：cookie是需要浏览器支持的，如果客户端禁用了cookie，则会话跟踪就会失效；运用session就需要使用URL重写的方式，所有用到session的URL都要进行重写，否则session会话跟踪也会失效。
- 跨域支持不同：cookie支持跨域访问，session不支持跨域访问。

>  请介绍session的工作原理


session依赖于cookie。

当客户端首次访问服务器时，服务器会为其创建一个session对象，该对象具有一个唯一标识SESSIONID。并且在响应阶段，服务器会创建一个cookie，并将SESSIONID存入其中。

客户端通过响应的cookie而持有SESSIONID，所以当它再次访问服务器时，会通过cookie携带这个SESSIONID。服务器获取到SESSIONID后，就可以找到与之对应的session对象，进而从这个session中获取该客户端的状态。

### 请求类型

>get请求与post请求有什么区别？

- GET在浏览器回退时是无害的，而POST会再次提交请求。
- GET产生的URL地址可以被Bookmark，而POST不可以。
- GET请求会被浏览器主动cache，而POST不会，除非手动设置。
- GET请求只能进行url编码，而POST支持多种编码方式。
- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
- GET请求在URL中传送的参数是有长度限制的，而POST没有。
- 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。
- GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
- GET参数通过URL传递，POST放在Request body中

> post不幂等是为什么？


HTTP方法的幂等性是指一次和多次请求某一个资源应该具有同样的副作用。幂等性属于语义范畴，正如编译器只能帮助检查语法错误一样，HTTP规范也没有办法通过消息格式等语法手段来定义它。

POST所对应的URI并非创建的资源本身，而是资源的接收者。比如：POST http://www.forum.com/articles的语义是在http://www.forum.com/articles下创建一篇帖子，HTTP响应中应包含帖子的创建状态以及帖子的URI。两次相同的POST请求会在服务器端创建两份资源，它们具有不同的URI。所以，POST方法不具备幂等性。

## tomcat
>tomcat 为什么要自定义类加载器
对于每一个应用都会有一个类加载器，把应用与应用类与类之间进行隔离，tomcat还利用类加载器进行热加载。

有重名的时候，公用一个类加载器就会冲突。
# 数据库
## acis
原子性、一致性、隔离性、持久性。
## 事务
> 事务的分类

- 扁平事务
  - 最简单的事务，从BEGIN WORK开始到COMMIT或者ROLLBACK WORK结束，要么全执行，要么全不执行
- 带有保存点的事务
  - 一个事务如果执行出现异常，全部放弃有点可惜，子啊事务中添加保存点，可以将数据库回滚到保存点发生的时间。
- 嵌套事务
  - 有一个顶级事务控制整体的流程，1有多个局部事务控制局部的变换。顶层事务之下的事务称为子事务。
- 链式事务
  - 保存点事务的一个变种。在提交事务的时候释放不需要的对象，将必要的上下文隐式的传递给下一个要开始的事务，提交事务和下一个事务开始是一个原子操作。下一个事务能够看得到上一个事务的结果就好像是同一个事务中一样。
- 分布式事务


## 关系型数据库
### 数据库的常见问题
> 数据库常见问题和解决方案

- 缓存穿透
  - 缓存中没有值，数据库中也没有值但是一直有大量的该数据的请求，每次先查缓存再查数据库浪费资源
  - 在第一次查询没有结果之后，在缓存中加入到这个key，设置值为null
  - 对请求参数做校验，过滤掉、拦截不合适的请求
  - 使用布隆过滤器记录下来未存在的值，已经查过了就不再去查
- 缓存击穿
  - 某时间大量的请求来查询某个值导致数据库崩溃
  - 缓存中key的过期时间保证在热点期中保留较长的时间
  - 使用互斥锁，在第一个线程访问查找的适合锁住，查完值将值存储到缓存当中之后，再释放锁。
  - 定时更新缓存
- 缓存雪崩 
  - 多个key突然在缓存中失效
  - 每个key的过期时间不一致
  - 启用降级和熔断措施：在发生雪崩时，若应用访问的不是核心数据，则直接返回预定义信息/空值/错误信息。或者在发生雪崩时，对于访问缓存接口的请求，客户端并不会把请求发给Redis，而是直接返回。
  - 使用高性能的分布式服务器
  - 缓存预热
- 双写不一致
  - 缓存中的值和数据库的值不一致
  - 先更新数据库、再删除缓存,如果第二步出现失败的情况，则可以采用重试机制解决问题。
  - ~~先删除缓存再删除数据库中的值~~，在高并发情况下的效性能较低，但是仍会出现数据不一致问题
  - 设置key的过期时间比较低，某些场景之下可以
  - 维护一个队列，先更新数据库再删除缓存，删除失败就放进队列，另一个任务不断的从队列中取任务尝试删除key
  - 维护一个读写队列，读写串行化，对于写操作，删除缓存后，写操作放进队列中等待
  - 或者采用***延时双删***，sleep x ms后，再次删除缓存




>mvcc  多版本并发控制

MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用READ COMMITTD、REPEATABLE READ这两种隔离级别的事务在执行普通的SEELCT操作时访问记录的版本链的过程。可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。READ COMMITTD、REPEATABLE READ这两个隔离级别的一个很大不同就是：生成ReadView的时机不同，READ COMMITTD在每一次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了。

在***读已提交***和***可重复读***的隔离级别下实现


`InnoDB` 的 MVCC ，是通过在每行记录后面保存**两个隐藏的列**来实现的。这两个列一个保存了行的创建时间，一个保存行的过期时间(或删除时间)，当然存储的并不是真正的时间，而是系统版本号。每开始一个事务，系统版本号就会自动递增，事务开始时刻的版本号作为当前事务的版本号，用来和查询到的每行记录的版本号就行比较。

以下是 `REPEATABLE READ` 的隔离级别下具体操作：

SELECT
InnoDB 会根据以下两个条件检查每行记录：
a. InnoDB 只查询版本早于当前事务版本的数据行（也就是，行的系统版本号小于或等于事务的系统版号），这样可以确保事务读取的行，要么是在事务开始前的已经存在的，要么是事务自身插入或者修改过的。
b. 行的删除版本要么未定义，要么大于当前事务版本号。这可以确保事务读取到的行，在事务开始之前未被删除。
只有符合上述两个条件的记录，才能返回作为查询结果
- INSERT
  - InnoDB 为新插入的每一行保存当前系统版本号作为行版本号
- DELETE
  - InnoDB 为删除的每一行保存当前系统版本号作为行删除标识
- UPDATE
  - InnoDB 为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识
  
保存着两个额外的系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行

mvcc的实现技术
- 隐藏列，一个是本行数据的事务id。指向undo log的指针等
- 基于undo log的版本链。每个undolog的日志中都会有指向上一个版本的undolog的指针，从而形成一条版本链
- ReadView 通过隐藏列和版本链可以将数据恢复到指定版本。版本的指定是由readview来指定的。事务在某一时刻给系统打快照，，之后在进行读操作的时候，会将读取到的数据id与快照对比，从而判断数据是是否对readview可见即是否对事务可见

>mysql的acid特性

- 原子性
  - undo log 是一种回滚日志，undolog记录事务开始前老版本数据，用于实现回滚，保证原子性，实现MVCC，会将数据修改前的旧版本保存在undolog，然后行记录有个隐藏字段回滚指针指向老版本。是一种逻辑日志，做之前相反的操作回滚到修改之前。
- 持久性
  - redo log是一种物理日志，会记录事务开启后对数据做的修改，crash-safe。特性：空间一定，写完后会循环写，有两个指针write pos指向当前记录位置，checkpoint指向将擦除的位置，redolog相当于是个取货小车，货物太多时来不及一件一件入库太慢了这样，就先将货物放入小车，等到货物不多或则小车满了或则店里空闲时再将小车货物送到库房。用于crash-safe，数据库异常断电等情况可用redo log恢复
- 隔离性
  - 锁+mvcc
- 一致性
  - 以上三种特性就是为了保证一致性

>mysql的主从复制

1. 主服务器将数据更改记录到二进制文件binlog中
2. 从服务器把主服务器的二级制日志复制到自己的relay日志中
3. 从服务器重做relay日志，将更改应用到自己的数据库中。
  
不是完全实时而是异步实时

### 索引
>mysql的索引

索引是一种在磁盘上存储的特殊物理结构，其中存储着表的每一行数据的引用。

- 普通索引和唯一索引
  - 普通索引可为空，可重复
  - 唯一索引不可重复，可为空
  - 主键索引不可重复，不为空
- 单列索引和组合索引
  - 组合索引遵循最左原则，sql语句中使用到了组合索引中的最左边的索引，这个sql语句就可以使用这个组合索引进行匹配
- 全文索引
  - 对于char，varchar，text，fulltext的列中使用索引，在列上支持全问文找
- 空间索引
  - 对空间类型且not null的字段进行的索引，只能在myisam引擎的表中存储。

可以到单独创建index也可以在创建表的时候创建index。在创建表的时候添加约束，主键约束，唯一约束，外键约束，定义约束的同时就相当于在列上创建了唯一的索引。

> 判断sql有没有走索引，index有没有生效

用`explain`语句

`explain select * from book where book_id = 1 ;`

> 创建索引的原则

- 查询更快
- 占据空间更小

- 最好是经常出现在where中的列
- 使用短索引，对长字符串进行索引最好指定一个前缀长度，这样能节省下来大量的空间。
- 尽量扩展索引而不是新建索引
- text，image，bit类型的列不建立索引

- 数据量小的表不需要创建index
- 更新过多的表不需要创建index
- 唯一性的列可以创建唯一索引
- 经常orderby的列或者groupby的几个列可以进行index
- 数据比较单一，例如性别只有男女就不需要建立索引 
- 频繁更新的列，参与列计算的列，不参与列计算的列不适合建索引

> 数据库索引失效
- 组合索引时，遵循最左原则
- 不在索引列上做任何操作，计算函数类型转换都会使得索引失效
- 尽量使用覆盖索引（index 列）少用`select *` 减少回表次数
- mysql在索引列上使用`!=`或者`<>`的时候索引会失效
- 使用 link '%' %开头的时候，索引会失效，转为全表扫描
- 少用 or or 连接的时候会发生全表扫描 
- innodb中发生了隐式转换,字符串不加单引号导致隐式转换
  - 在两边数据类型不一致时，数字类型默认会转化为精度更高的比较，字符串和整数默认转化为浮点数进行比较，当对索引列上的值进行操作的时候索引就会失效

> 索引的实现原理

索引的底层实现都是和表的存储引擎相关的。

MyISAM的底层实现。索引是以B+树的形式存储。主索引和辅助索引没有什么区别，只是主索引不允许重复，主索引的data域存储的是行记录数据地址的引用。辅助索引的data域记录数据记录的地址。

Innodb也是以B+树的形式存储的。只是Innodb本身表数据就是一个B+树。innodb表会按照指定的主键建立b+树，若是没有指定会选择一个不重复的列作为主键，或者自己生成一个6字节的长整型数字作为主键存储数据地址。 innodb的辅助索引的data域会存放数据的主键。查询辅助索引会再次查询主索引。相当于查询两次索引找到数据。

过长的字段，或者非单调的字段不适合作为innodb的主键。而推荐使用自增主键。

> 数据库索引的重建过程

> 数据库索引什么时候重建

表上频繁发生delete，insert操作的时候
发生了after table move move导致rowid发生变化

>怎么判断表索引需要重建了

看表索引是否倾斜的严重，是否浪费空间，对表索引进行结构分析

`analyze index index_name validate structure;`

在相同的session中查询index_stats表

`select height,DEL_LF_ROWS/LF_ROWS from index_stats;`

`height>=4`或者`ELD_LF_ROWS/LF_ROWS>0.2`的情况下就应该考虑重新建立索引

> 如何重建索引

1、drop掉原索引然后再创建索引
```sql
drop index index_name;
create index index_name on table_name (column_name);
```
2、直接重建索引

```sql
alter index index_name rebuild;
alter index index_name rebuild online;
```
此方法较快。使用原有索引项重建索引。

若是在重建索引的过程当中有其他用户在对这个表进行操作，尽量使用online来避免索引重建的时候表的加锁问题。但是本方法需要额外的物理空间。索引建立完成后将老索引删除，若是重建失败也不会影响原来的索引，可以使用本方法来进行索引物理空间的迁移。


rebuild重建索引的过程。

- 1、rebuild采用index fast scan 或者table full scan的方式读取原索引中的数据重建一个索引，采用哪种取决于cost。rebuild online采用全表扫描的方法获取数据。rebuild过程当中有排序操作。
- 2、rebuild会阻塞DML操作，rebuild online不会阻塞DML操作
- 3、rebuild online过程当中系统会产生一个系统临时日志表，临时日志中记录online过程当中索引的变化，系统将日志表中的记录维护到新的索引之后就删除老索引。

注意事项

- 1、注意新建索引有充足的物理空间
- 2、虽然online不阻塞DML操作但还是尽量选在DML操作最少的时间段内进行。
- 3、rebuild操作会产生大量的redo log

> 如何在in 模糊查询使用索引

in字符串要添加单引号

模糊查询`"%"`百分号放在开头是不能够使用索引`index`。可以加入冗余列，冗余列为模糊查询列的倒序列、反转序列。

> index为什么使用B+树

因为B+树的查询次数在2~4次之间，高扇出性

> hash查询和B+树查询的区别

hash索引的底层就是Hash表，往往只通过hash计算就可以得到对应的键值，然后回表查询数据，而b+树的查询是从根节点出发知道查找到叶子节点才算结束。一般要经历2~4次查询，再根据具体情况决定要不要回表查询。

- hash的性能不稳定，数据量过大容易发生hash碰撞而B+树性能稳定。
- hash不支持索引进行排序，b+树支持
- hash不支持范围查询，模糊查询，最左索引匹配，而b+树支持
- 有些时候b+树不需要回表查询例如聚簇索引，Innodb的主键索引

> 特殊情况下使用b+树查询
> 聚簇索引和非聚簇索引

聚簇索引是将数据的索引和数据行对应的放在一起，找到索引就找到了数据。

非聚簇索引是将索引放在内存中，通过查询内存中的索引再去磁盘中查询真正的数据行的存储位置

聚簇索引之上建立的都是辅助索引，非聚簇索引都是辅助索引。

一个表只有一个聚簇索引，设置主键做为聚簇索引的时候最好将主键设置为`auto_increment`自增。

聚簇索引的优势

- 由于行数据和叶子节点存储在一起，同一页中会有多条行数据，访问同一数据页不同行记录时，已经把页加载到了Buffer中，再次访问的时候，会在内存中完成访问，不必访问磁盘。这样主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回了，如果按照主键Id来组织数据，获得数据更快。
- 辅助索引使用主键作为"指针"而不是使用地址值作为指针的好处是，减少了当出现行移动或者数据页分裂时辅助索引的维护工作，使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是InnoDB在移动行时无须更新辅助索引中的这个"指针"。也就是说行的位置（实现中通过16K的Page来定位）会随着数据库里数据的修改而发生变化（前面的B+树节点分裂以及Page的分裂），使用聚簇索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响。
- 聚簇索引适合用在排序的场合，非聚簇索引不适合
- 取出一定范围数据的时候，使用用聚簇索引
- 二级索引需要两次索引查找，而不是一次才能取到数据，因为存储引擎第一次需要通过二级索引找到索引的叶子节点，从而找到数据的主键，然后在聚簇索引中用主键再次查找索引，再找到数据
- 可以把相关数据保存在一起。例如实现电子邮箱时，可以根据用户 ID 来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘 I/O。

聚簇索引的劣势

- 维护索引很昂贵，特别是插入新行或者主键被更新导至要分页(page split)的时候。建议在大量插入新行后，选在负载较低的时间段，通过OPTIMIZE TABLE优化表，因为必须被移动的行数据可能造成碎片。使用独享表空间可以弱化碎片
表因为使用UUId（随机ID）作为主键，使数据存储稀疏，这就会出现聚簇索引有可能有比全表扫面更慢，

- 主键的值是顺序的，所以 InnoDB 把每一条记录都存储在上一条记录的后面。当达到页的最大填充因子时（InnoDB 默认的最大填充因子是页大小的 15/16，留出部分空间用于以后修改），下一条记录就会写入新的页中。一旦数据按照这种顺序的方式加载，主键页就会近似于被顺序的记录填满（二级索引页可能是不一样的）

如果主键比较大的话，那辅助索引将会变的更大，因为辅助索引的叶子存储的是主键值；过长的主键值，会导致非叶子节点占用占用更多的物理空间

> B+树的优势

优势提醒在查找效率上。

B+树的树干上只有索引，数据存在叶子节点上，因此更加矮胖，IO次数更少。

B+树每次必须查找到叶子节点上，查找效率稳定。

1. 单一节点存储更多的元素，使得查询的IO次数更少；
2. 所有查询都要查找到叶子节点，查询性能稳定；
3. 所有叶子节点形成有序链表，便于范围查询。


>索引覆盖
要查询的字段刚好是已存在的索引中的字段。
索引覆盖就是一个SQL在执行时，可以利用索引来快速查找，并且此SQL所要查询的字段在当前索引对应的字段中都包含了，那么就表示此SQL走完索引后不用回表了，所需要的字段都在当前索引的叶子节点上存在，可以直接作为结果返回了

### sql

>分页查询的偏移量非常大的时候如何优化查询

- 在页面中限制分页的数量
- 优化大偏移量的性能
  - 先按照limit 10000，20 查询对应的id主键，再按照id或主键查询需要的行列，做一次关联操作
  - 使用一些唯一的或者有大小顺序的列作为书签，记录下来low-high，再找个基础进行查询

> 预防sql注入

- 严格的参数校验
- sql预编译
### 范式
一般满足第三范式即可
- 第一范式
  - 每个属性被严格分割，没有出现数组、集合之类的列，每一列都是不可分割的原子列
- 第二范式
  - 每个非码属性都必须依赖侯选码，每个示例或者记录都必须严格的区分
- 第三范式
  - 减少数据冗余，，减少传递依赖。一个关系中不包含在其他关系中已经包含的非主关键字信息
### 锁
锁的类型
- 共享锁S lock 允许事务读一行数据
- 排他锁X lock 允许数据删除或更新一行数据

s，x都是行锁

锁的粒度

行级的锁和表级别的锁，间隙锁（锁的是一个范围），额外的锁，


意向锁


意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度上进行加锁。

- 意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁。
- 意向排他锁（IX Lock），事务想要获得一张表中某几行的排他锁。

于InnoDB存储引擎支持的是行级别的锁，因此意向锁其实不会阻塞除全表扫以外的任何请求。

锁的算法
= record lock 单个记录上的锁
- gap lock 间隙锁，锁定一个范围但不包含锁本身
- Next-key lock ：gap lock+record lock锁定一个范围同时锁定记录本身
  
> 间隙锁

间隙锁属于行级锁，锁定一个范围，但是不包含记录本身，避免多个事务将记录插入到同一个范围中，避免发生幻读的情况
>innodb的行级锁是怎么实现的

给索引上的索引项加锁来实现的，通过索引条件来查询才会使用行级锁，否则使用行锁

> 锁升级

一般指行锁升级到页锁，页锁升级到表锁，innodb一般是以页锁为基本单位无论加锁的是一行还是多行数据不存在升级问题，开销基本一致
### 数据库的优化
> 数据库的优化

减少系统的瓶颈，减少资源的占用，增加系统的相应速度，

- 优化文件系统，提示io速度。
- 优化系统操作调度策略，提高mysqk在高负荷情况下的负载能力
- 优化表结构，索引查询语句等使得查询结果更快

- 针对查询，使用索引，使用连接的方式代替子查询
- 针对慢查询，通过查询慢查询日志，分析原因有针对的优化
- 针对插入，可以先禁用索引和检查，在插入完成之后再开启索引和检查
- 针对表结构，可以擦划分较大的表分为多张表，增加中间表，增加冗余字段等方式进行优化。

> 数据库的日志

- binlog
  - 以二进制的形式存储的日志。记录了所有的对于数据库的操作，包括执行时间，执行消耗的资源，以及相关的事务信息，是默认开启的
- redo log
  - 重做日志是为了实现日志的持久性，一般分为内存中的重做日志缓存，是易失的，和重做日志文件，是持久的。Innodb 是事务的存储引擎，innodb force at commit，当事务提交的时候，必须先将该事务的所有日志写进重做日志文件进行持久化等待该事务的commit操作完成才算完成一个事务。这里的日志指的是redo log 和undolog undolog保证的是数据的原子性。用于事务的回滚和mvcc功能。redo log基本上是顺序写的，数据库允许是不需要对redo log进行读操作。undo log需要进行随机读写的。
- undolog
  - undo存放在数据库内部的一个特殊空间内，成为undo段，位于表共享空间内

### 数据库的引擎
- Innodb引擎
  - Innodb引擎是一个具有提交回滚崩溃恢复处理能力的acid存储引擎，Innodb在锁定行之后也为select语句提供一个非锁定读。Innodb的表可以与其他类型的表一起存储，甚至是在同一个查询中混合。
  - Innodb引擎是为巨大数据量处理提供的最大性能设计，cpu效率高于其他类型的引擎
  - Innodb存储引擎完全与mysql服务器整合。为内存中缓存数据和索引而维护自己的缓冲池。Innodb将它的表和索引存储在一片逻辑空间中，表空间可以包含数个文件，可以是任意尺寸，即使超出文件大小有限定的操作系统上。
  - Innodb支持外键完整性约束。Innodb为每行数据提供一个主键，若是没有显示定位的话，就生成一个6B的rowid来表示主键。
  - Innodb被应用到需要高性能的大型数据库站点上。Innodb自己不创建目录，mysql将在数据目录下创建一个字段扩展文件，和两个日志文件
- MyISAM，扩展ISAM引擎，较高的查询和插入速度
  -  在支持大文件的操作系统上被支持
  -  当把删除和更改插入操作混合使用的时候，动态尺寸的行会产生更多的碎片需要合并下一块空间进行扩展
  -  每个MyISAM最大的索引数是64，可以通过重新编译来改变，每个索引的列可以有16个
  -  最大的键长度为1000B，长度超过250B后，一个超过1024的键将被用上。
  -  BLOB和text的列可以被索引
  -  null允许出现在索引的列里面
  -  数字以高位数字优先被存储，以允许一个更高的索引压缩
  -  每个表的auto_increment的内部处理，，插入删除的时候auto_increment更快。但是序列顶的值被删除之后就不能够在被使用
  -  可以把数据文件和索引文件放在不同的空间存储
  -  varchar列和char列可以固定或者动态记录长度
  -  不同的列可以有不同的字符集
  -  varchar列和char列可以最多64kb
  -  不支持事务
  -  支持表级锁
  -  存储表的总行数

> innodb如何实现事务的

Innodb通过Buffer Pool，LogBuffer，Redo Log，Undo Log来实现事务，以一个update语句为例：
1. Innodb在收到一个update语句后，会先根据条件找到数据所在的页，并将该页缓存在Buffer Pool中
2. 执行update语句，修改Buffer Pool中的数据，也就是内存中的数据
3. 针对update语句生成一个RedoLog对象，并存入LogBuffer中
4. 针对update语句生成undolog日志，用于事务回滚
5. 如果事务提交，那么则把RedoLog对象进行持久化，后续还有其他机制将Buffer Pool中所修改的数据页持久化到磁盘中
6. 如果事务回滚，则利用undolog日志进行回滚

### explain语句的含义
|列名|描述|
|----|----|
|id|查询语句中每出现一个SELECT关键字，MySQL就会为它分配一个唯一的id值，某些子查询会被优化为join查询，那么出现的id会一样|
|select_type|SELECT关键字对应的那个查询的类型|
|table|表名|
|partitions|匹配的分区信息|
|type|针对单表的查询方式（全表扫描、索引）|
|possible_keys|可能用到的索引|
|key|实际上使用的索引|
|key_len|实际使用到的索引长度|
|ref|当使用索引列等值查询时，与索引列进行等值匹配的对象信息|
|rows|预估的需要读取的记录条数|filtered|某个表经过搜索条件过滤后剩余记录条数的百分比|
|Extra|一些额外的信息，比如排序等|
## NoSql数据库
### redis

> redis速度快的原因

- redis 将数据存储在内存中相比于数据库中的读取要快
- redis 是单线程的省去很多线程切换，加锁解锁的时间
- redis 使用io多路复用技术可以处理并发的连接
  - Redis使用I/O多路复用来监听多个socket链接客户端，这样就可以使用一个线程链接来处理多个请求
- 存储的基本数据结构简单

redis可以多开几个进程来避免单线程的问题，redis没有约束，只需要分辨出用户的数据是在那个服务器或者是进程上就可以

多路复用用来解决一个io阻塞影响其他io的问题

redis的io多路复用

Redis基于Reactor模式开发了网络事件处理器、文件事件处理器 fileeventhandler。它是单线程的， 所以 Redis才叫做单线程的模型，它采用IO多路复用机制来同时监听多个Socket，根据Socket上的事件类型来选择对应的事件处理器来处理这个事件。可以实现高性能的网络通信模型，又可以跟内部其他单线程的模块进行对接，保证了 Redis内部的线程模型的简单性。

文件事件处理器的结构包含4个部分：多个Socket、IO多路复用程序、文件事件分派器以及事件处理器
（命令请求处理器、命令回复处理器、连接应答处理器等）。
多个 Socket 可能并发的产生不同的事件，IO多路复用程序会监听多个 Socket，会将 Socket 放入一个队列中排队，每次从队列中有序、同步取出一个 Socket 给事件分派器，事件分派器把 Socket 给对应的事件处理器。
然后一个 Socket 的事件处理完之后，IO多路复用程序才会将队列中的下一个 Socket 给事件分派器。文件事件分派器会根据每个 Socket 当前产生的事件，来选择对应的事件处理器来处理。
Redis启动初始化时，将连接应答处理器跟AE_READABLE事件关联。

若一个客户端发起连接，会产生一个AE_READABLE事件，然后由连接应答处理器负责和客户端建立连接，创建客户端对应的socket，同时将这个socket的AE_READABLE事件和命令请求处理器关联，使得客户端可以向主服务器发送命令请求。

当客户端向Redis发请求时（不管读还是写请求），客户端socket都会产生一个AE_READABLE事件，触发命令请求处理器。处理器读取客户端的命令内容， 然后传给相关程序执行。

当Redis服务器准备好给客户端的响应数据后，会将socket的AE_WRITABLE事件和命令回复处理器关联，当客户端准备好读取响应数据时，会在socket产生一个AE_WRITABLE事件，由对应命令回复处理器处理，即将准备好的响应数据写入socket，供客户端读取。
命令回复处理器全部写完到 socket 后，就会删除该socket的AE_WRITABLE事件和命令回复处理器的映射。


>Redis在持久化时fork出一个子进程，这时已经有两个进程了，怎么能说是单线程呢？

Redis是单线程的，主要是指Redis的网络IO和键值对读写是由一个线程来完成的。而Redis的其他功能，如持久化、异步删除、集群数据同步等，则是依赖其他线程来执行的。所以，说Redis是单线程的只是一种习惯的说法，事实上它的底层不是单线程的

#### Redis的数据结构

Redis的数据结构有：
- 字符串：可以用来做最简单的数据，可以缓存某个简单的字符串，也可以缓存某个json格式的字符串，Redis分布式锁的实现就利用了这种数据结构，还包括可以实现计数器、Session共享、分布式ID
- 哈希表：可以用来存储一些key-value对，更适合用来存储对象
- 列表：Redis的列表通过命令的组合，既可以当做栈，也可以当做队列来使用，可以用来缓存类似微信公众号、微博等消息流数据
- 集合：和列表类似，也可以存储多个元素，但是不能重复，集合可以进行交集、并集、差集操作，从而可以实现类似，我和某人共同关注的人、朋友圈点赞等功能
- 有序集合：集合是无序的，有序集合可以设置顺序，可以用来实现排行榜功能
#### redis的锁
> redis 实现分布式锁

setnx命令，set if not exists 

expire 命令，设置过期时间

setnx命令返回整数值，当返回1时表示设置值成果，当返回0时表示设置值失败（key已存在

setnx可以实现分布式锁，但是会有隐患。在某线程a为执行完毕而锁到期释放，到线程a执行时间结束之后，线程a再次释放锁，要么出现异常，要么就会释放掉其他线程例如b在锁自动释放后加的，不属于线程啊而属于b的锁

在加锁时就要给锁设置一个标识，进程要记住这个标识。当进程解锁的时候，要进行判断，是自己持有的锁才能释放，否则不能释放。可以为key赋一个随机值，来充当进程的标识。

解锁时要先判断、再释放，这两步需要保证原子性，否则第二步失败的话，就会出现死锁。而获取和删除命令不是原子的，这就需要采用Lua脚本，通过Lua脚本将两个命令编排在一起，而整个Lua脚本的执行是原子的。

1. 使用lua脚本
   lua脚本保证原子性
```java
public boolean tryLock_with_lua(String key, String UniqueId, int seconds) {
    String lua_scripts = "if redis.call('setnx',KEYS[1],ARGV[1]) == 1 then" +
            "redis.call('expire',KEYS[1],ARGV[2]) return 1 else return 0 end";
    List<String> keys = new ArrayList<>();
    List<String> values = new ArrayList<>();
    keys.add(key);
    values.add(UniqueId);
    values.add(String.valueOf(seconds));
    Object result = jedis.eval(lua_scripts, keys, values);
    //判断是否成功
    return result.equals(1L);
}

```
2. 整合到一起的两个命令
```shell
SET key value[EX seconds][PX milliseconds][NX|XX]
```
```java
public boolean tryLock_with_set(String key, String UniqueId, int seconds) {
    return "OK".equals(jedis.set(key, UniqueId, "NX", "EX", seconds));
}
```

1. 首先利用setnx来保证：如果key不存在才能获取到锁，如果key存在，则获取不到锁
2. 然后还要利用lua脚本来保证多个redis操作的原子性
3. 同时还要考虑到锁过期，所以需要额外的一个看门狗定时任务来监听锁是否需要续约
4. 同时还要考虑到redis节点挂掉后的情况，所以需要采用红锁的方式来同时向N/2+1个节点申请锁，都申请到了才证明获取锁成功，这样就算其中某个redis节点挂掉了，锁也不能被其他客户端获取到

锁的释放
```java
public boolean releaseLock_with_lua(String key,String value) {
    String luaScript = "if redis.call('get',KEYS[1]) == ARGV[1] then " +
            "return redis.call('del',KEYS[1]) else return 0 end";
    return jedis.eval(luaScript, Collections.singletonList(key), Collections.singletonList(value)).equals(1L);
}

```

#### redis的持久化

> redis的持久化策略

redis的持久化策略分为AOF，RDB ，RDB-AOF混合持久化策略。

- RDB（Redis Database）策略
  - 是redis的默认持久化策略
  - 是通过快照的形式将当前进程的数据的键值对持久化到硬盘中，会创建一个压缩过的二进制文件.rdb文件。
  - RDB的触发方式有两种
    - 自动触发 ，通过命令save或者bgsave进行触发，创建rdb文件
    - 通过配置选项，使得在满足某些条件的时候触发BGSAVE命令。
  - 执行命令，手动触发
    - save命令执行期间服务器会阻塞，直到.rdb文件创建完为止，已经弃用。
    - bgsave是save的异步版。bgsave会先使得父进程创建 fork一个子进程，子进程完全共享父进程的数据，在创建子进程的时候服务器会短暂阻塞，之后服务器会继续处理自己的请求，子进程会创建.rdb文件并存储父进程的数据。父进程得到通知用新的.rdb文件取代旧的.rdb文件。在子进程创建.rdb文件的过程当中，任意进程修改数据都会对该页数据进行复制然后修改副本。
    - 自动触发：
      - save m n ：在 m 秒内，如果有 n 个键发生改变，则自动触发持久化，通过bgsave执行，如果设置多个、只要满足其一就会触发，配置文件有默认配置(可以注释掉)
      - flushall：用于清空redis所有的数据库，flushdb清空当前redis所在库数据(默认是0号数据库)，会  清空RDB文件，同时也会生成dump.rdb、内容为空
      - 主从同步：全量同步时会自动触发bgsave命令，生成rdb发送给从节点
  - 优点
    - RDB生成紧凑压缩的二进制文件，体积小。生成恢复数据的速度快
  - 缺点
    - RDb方法会频繁创建子进程，属于重量级操作，不宜频繁进行，无法做到实时监控，RDB无法做到实时的持久化
- AOF(Append Only File)
  - Redis持久化的主流方式
  - AOF以独立日志的形式记录了每次写入的命令，重启后再次执行aof文件中国的命令来恢复数据。
  - 工作流程
    - 命令写入
    - 文件同步
    - 文件重写
    - 重启加载
  - aof默认不开启 ，修改配置项 `appendonly yes`
  - AOF以文本协议写入命令
    - 文本协议具有很好的兼容性；
    - 直接采用文本协议格式，可以避免二次处理的开销；
    - 文本协议具有可读性，方便直接修改和处理
  - 文件同步机制
    - 为了提高程序的写入性能，现代操作系统会把针对硬盘的多次写操作优化为一次写操作。
    - 当程序调用write对文件写入时，系统不会直接把数据写入硬盘，而是先将数据写入内存的缓冲区中；- 当达到特定的时间周期或缓冲区写满时，系统才会执行flush操作，将缓冲区中的数据冲洗至硬盘中；- 这种优化机制虽然提高了性能，但也给程序的写入操作带来了不确定性。
    - 对于AOF这样的持久化功能来说，冲洗机制将直接影响AOF持久化的安全性；
    - 为了消除上述机制的不确定性，Redis向用户提供了appendfsync选项，来控制系统冲洗AOF的频率；
      - Linux的glibc提供了fsync函数，可以将指定文件强制从缓冲区刷到硬盘，上述选项正是基于此函数
    - appendfsync的取值
      - always 每个写入命令都会冲洗，停机的时候最多丢失一个命令，但会大大降低redis的性能。
      - everysec 每秒进行一次冲洗，停机最多丢失一秒之内的数据。兼顾安全性和性能的折中方案
      - no 不主动进行冲洗，有操作系统自己决定。
  - 优点
    - AOF持久化要安全很多，比RDB持久化会丢失大量数据相比。，可以将丢失的数据量控制在1秒之内。
    - AOF 机制的 rewrite 模式。定期对AOF文件进行重写，以达到压缩的目的
  - 缺点
    - AOF存储的是协议文本，体积比RDb要大很多，AOF通过命令来恢复数据，比RDb要慢很多。AOF在重写的时候也会创建子进程，在数据库较大的时候将占用大量的资源会导致数据库的短暂阻塞。
- RDB-AOF混合持久化
  - 这种模式是基于AOF持久化构建而来的。用户可以通过配置文件中的“aof-use-rdb-preamble yes”配置项开启AOF混合持久化
  - 数据处理
    - 像BGSAVE一样数据库根据当前的状态生成对应的RDB数据，并将其写入到AOF文件中。
    - 对于重写之后的Redis命令，则以文本协议的形式追加到AOF文件的末尾即RDB数据之后
  - 使用RDB-AOF混合持久化，用户可以同时获得RDB持久化和AOF持久化的优点，服务器既可以通过AOF文件包含的RDB数据来实现快速的数据恢复操作，又可以通过AOF文件包含的AOF数据来将丢失数据的时间窗口限制在1s之内。

#### redis的高可用性策略
>实现redis的高可用性

主要通过集群和哨兵两种方式实现
- 哨兵
  - 哨兵节点会定期监控数据节点，其他哨兵节点是否可达；
  - 哨兵节点会将故障转移的结果通知给应用方
  - 哨兵节点也是独立的Redis节点，是特殊的Redis节点，它们不存储数据，只支持部分命令
  - 节点的故障判断是由多个哨兵节点共同完成的，可有效地防止误判
- 集群
  - Redis集群采用虚拟槽分区来实现数据分片，它把所有的键根据哈希函数映射到0-16383整数槽内，计算公式为slot=CRC16(key)&16383，每一个节点负责维护一部分槽以及槽所映射的键值数据。虚拟槽分区具有如下特点：
  - 解耦数据和节点之间的关系，简化了节点扩容和收缩的难度；  
  - 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据；  
  - 支持节点、槽、键之间的映射查询，用于数据路由，在线伸缩等场

> redis主从，哨兵，集群有什么区别

Redis主从就是常见的主从模式，从节点自动同步主节点数据，实现数据的热备份。

Redis哨兵就是在Redis主从上添加了一个监控系统（Redis Sentinel系统），实现故障转移，Redis哨兵会监控Redis主从节点运行状态，当主节点故障下线后，Redis哨兵会选择一个从节点充当新的主节点，继续提供服务。

Redis集群在Redis主从上添加了监控机制和数据分片机制（Redis中是分槽位），实现故障转移和数据水平扩展，Redis集群中组合了多个Redis主从，并且每个Redis主节点都负责存储集群中的一部分数据，当某个主节点故障下线后，Redis集群会选择该节点的一个从节点充当新的主节点，继续提供服务。

生产环境应该很少使用单纯的Redis主从吧，如果数据量比较少，可以使用哨兵模式，但Redis集群的稳定性、可扩展性都优于哨兵模式，所以使用Redis集群的场景应该是最多的吧。


> redis的watch

watch基于乐观锁，为了保证事务中的数据没有被其他应用修改。watch命令对key进行监视，有key发送了变化，就拒绝执行客户端提交的事务并给它返回一个空值。

> 设置key的过期时间

热点数据应当设置较大过期时间，或不设置，以避免缓存击穿

设置缓存时间的时候，可以附加一个随机数以避免缓存雪崩的情况


> redis的主从同步是如何实现的

Redis使用psync命令完成主从数据同步，同步过程分为全量复制和部分复制。全量复制一般用于初次复制的场景，部分复制则用于处理因网络中断等原因造成数据丢失的场景。psync命令需要以下参数的支持：

- 复制偏移量：主节点处理写命令后，会把命令长度做累加记录，从节点在接收到写命令后，也会做累加记录；从节点会每秒钟上报一次自身的复制偏移量给主节点，而主节点则会保存从节点的复制偏移量。
- 积压缓冲区：保存在主节点上的一个固定长度的队列，默认大小为1M，当主节点有连接的从节点时被创建；主节点处理写命令时，不但会把命令发送给从节点，还会写入积压缓冲区；缓冲区是先进先出的队列，可以保存最近已复制的数据，用于部分复制和命令丢失的数据补救。
- 主节点运行ID：每个Redis节点启动后，都会动态分配一个40位的十六进制字符串作为运行ID；如果使用IP和端口的方式标识主节点，那么主节点重启变更了数据集（RDB/AOF），从节点再基于复制偏移量复制数据将是不安全的，因此当主节点的运行ID变化后，从节点将做全量复制


> redis的缓存淘汰策略

当redis的写u人数据超过maxmemory之后Redis会根据maxmemory-policy指定的策略进行数据淘汰  

|策略|	描述|	版本|
|----|----|----|
|noeviction|	直接返回错误；	|
|volatile-ttl	|从设置了过期时间的键中，选择过期时间最小的键，进行淘汰；|	
|volatile-random	|从设置了过期时间的键中，随机选择键，进行淘汰；	||
|volatile-lru	|从设置了过期时间的键中，使用LRU算法选择键，进行淘汰；|	|
|volatile-lfu	|从设置了过期时间的键中，使用LFU算法选择键，进行淘汰；|4.0|
|allleys-random	|从所有的键中，随机选择键，进行淘汰；|	
|allkeys-lru	|从所有的键中，使用LRU算法选择键，进行淘汰；|	
|allkeys-lfu	|从所有的键中，使用LFU算法选择键，进行淘汰；|	4.0|

> redis的过期策略

两种过期策略

- 惰性删除：客户端访问一个key的时候，Redis会先检查它的过期时间，如果发现过期就立刻删除这个key。
- 定期删除：Redis会将设置了过期时间的key放到一个独立的字典中，并对该字典进行每秒10次的过期扫描，

过期扫描不会遍历字典中所有的key，而是采用了一种简单的贪心策略。该策略的删除逻辑如下：

- 从过期字典中随机选择20个key；
- 删除这20个key中已过期的key；
- 如果已过期key的比例超过25%，则重复步骤


redis中同时使用两种策略

>请介绍Redis集群的实现方案

Redis集群的分区方案：

Redis集群采用虚拟槽分区来实现数据分片，它把所有的键根据哈希函数映射到0-16383整数槽内，计算公式为slot=CRC16(key)&16383，每一个节点负责维护一部分槽以及槽所映射的键值数据。虚拟槽分区具有如下特点：
- 解耦数据和节点之间的关系，简化了节点扩容和收缩的难度；
- 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据；
- 支持节点、槽、键之间的映射查询，用于数据路由，在线伸缩等场景

Redis集群的功能限制：

Redis集群方案在扩展了Redis处理能力的同时，也带来了一些使用上的限制：

- key批量操作支持有限。如mset、mget，目前只支持具有相同slot值的key执行批量操作。对于映射为不同slot值的key由于执行mset、mget等操作可能存在于多个节点上所以不被支持。
- key事务操作支持有限。同理只支持多key在同一节点上的事务操作，当多个key分布在不同的节点上时无法使用事务功能。
- key作为数据分区的最小粒度，因此不能将一个大的键值对象（如hash、list等）映射到不同的节点。
- 不支持多数据库空间。单机下的Redis可以支持16个数据库，集群模式下只能使用一个数据库空间，即DB0。
- 复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。


- Redis集群的通信方案：



在分布式存储中需要提供维护节点元数据信息的机制，所谓元数据是指：节点负责哪些数据，是否出现故障等状态信息。常见的元数据维护方式分为：集中式和P2P方式。

Redis集群采用P2P的Gossip（流言）协议，Gossip协议的工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息，这种方式类似流言传播。通信的大致过程如下：
- 集群中每个节点都会单独开辟一个TCP通道，用于节点之间彼此通信，通信端口号在基础端口号上加10000；
- 每个节点在固定周期内通过特定规则选择几个节点发送ping消息；
- 接收ping消息的节点用pong消息作为响应。

其中，Gossip协议的主要职责就是信息交换，而信息交换的载体就是节点彼此发送的Gossip消息，Gossip消息分为：meet消息、ping消息、pong消息、fail消息等。

- meet消息：用于通知新节点加入，消息发送者通知接受者加入到当前集群。meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换。
- ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息，用于检测节点是否在线和交换彼此状态信息。ping消息封装了自身节点和一部分其他节点的状态数据。
- pong消息：当接收到meet、ping消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内封装了自身状态数据，节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。
- fail消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。

虽然Gossip协议的信息交换机制具有天然的分布式特性，但它是有成本的。因为Redis集群内部需要频繁地进行节点信息交换，而ping/pong消息会携带当前节点和部分其他节点的状态数据，势必会加重带宽和计算的负担。所以，Redis集群的Gossip协议需要兼顾信息交换的实时性和成本的开销。

- 集群里的每个节点默认每隔一秒钟就会从已知节点列表中随机选出五个节点，然后对这五个节点中最长时间没有发送过PING消息的节点发送PING消息，以此来检测被选中的节点是否在线。
- 如果节点A最后一次收到节点B发送的PONG消息的时间，距离当前时间已经超过了节点A的超时选项设置时长的一半（cluster-node-timeout/2），那么节点A也会向节点B发送PING消息，这可以防止节点A因为长时间没有随机选中节点B作为PING消息的发送对象而导致对节点B的信息更新滞后。
- 每个消息主要的数据占用：slots槽数组（2KB）和整个集群1/10的状态数据（10个节点状态数据约1KB）。


#### redis的事务实现

redis的事务没有回滚，只能实现原子性，一致性。

一致性有rof，rdb保证。

隔离性 redis是单线程处理数据的读写，因此可以保证隔离性

watch命令可以监控所有的key，为了保证事务中的数据没有被其他应用修改。


1、事务开始

`MULTI`命令的执行，标识着一个事务的开始。`MULTI`命令会将客户端状态的flags属性中打开REDIS_MULTI标识来完成的。

2、命令入队

当一个客户端切换到事务状态之后，服务器会根据这个客户端发送来的命令来执行不同的操作。如果客户端发送的命令为MULTI、EXEC、WATCH、DISCARD中的一个，立即执行这个命令，否则将命令放入一个事务队列里面，然后向客户端返回QUEUED回复

- 如果客户端发送的命令为 `EXEC`、`DISCARD`、`WATCH`、`MULTI` 四个命令的其中一个，那么服务器立即执行这个命令。 
- 如果客户端发送的是四个命令以外的其他命令，那么服务器并不立即执行这个命令。

首先检查此命令的格式是否正确，如果不正确，服务器会在客户端状态（redisClient）的 flags 属性关闭 REDIS_MULTI 标识，并且返回错误信息给客户端。

如果正确，将这个命令放入一个事务队列里面，然后向客户端返回 QUEUED 回复 

事务队列 是按照FIFO的方式保存入队的命令

3、事务执行

客户端发送 EXEC 命令，服务器执行 EXEC 命令逻辑。

- 如果客户端状态的 flags 属性不包含 `REDIS_MULTI` 标识，或者包含 `REDIS_DIRTY_CAS` 或者 `REDIS_DIRTY_EXEC` 标识，那么就直接取消事务的执行。
- 否则客户端处于事务状态（flags 有 `REDIS_MULTI` 标识），服务器会遍历客户端的事务队列，然后执行事务队列中的所有命令，最后将返回结果全部返回给客户端；

- redis 不支持事务回滚机制，但是它会检查每一个事务中的命令是否错误。
- Redis 事务不支持检查那些程序员自己逻辑错误。例如对 String 类型的数据库键执行对 HashMap 类型的操作！


- WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。
- MULTI命令用于开启一个事务，它总是返回OK。MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。
- EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。当操作被打断时，返回空值 nil 。
通过调用
- DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。
- UNWATCH命令可以取消watch对所有key的监控。



# 服务器

# 分布式
## 基础理论
> 什么是CAP理论

CAP理论是分布式领域中非常重要的一个指导理论，C（Consistency）表示强一致性，A（Availability）表示可用性，P（Partition Tolerance）表示分区容错性，CAP理论指出在目前的硬件条件下，一个分布式系统是必须要保证分区容错性的，而在这个前提下，分布式系统要么保证CP，要么保证AP，无法同时保证CAP。

分区容错性表示，一个系统虽然是分布式的，但是对外看上去应该是一个整体，不能由于分布式系统内部的某个结点挂点，或网络出现了故障，而导致系统对外出现异常。所以，对于分布式系统而言是一定要保证分区容错性的。

强一致性表示，一个分布式系统中各个结点之间能及时的同步数据，在数据同步过程中，是不能对外提供服务的，不然就会造成数据不一致，所以强一致性和可用性是不能同时满足的。

可用性表示，一个分布式系统对外要保证可用。

>什么是BASE理论

由于不能同时满足CAP，所以出现了BASE理论：
- BA：Basically Available，表示基本可用，表示可以允许一定程度的不可用，比如由于系统故障，请求时间变长，或者由于系统故障导致部分非核心功能不可用，都是允许的
- S：Soft state：表示分布式系统可以处于一种中间状态，比如数据正在同步
- E：Eventually consistent，表示最终一致性，不要求分布式系统数据实时达到一致，允许在经过一段时间后再达到一致，在达到一致过程中，系统也是可用的

> 什么是RPC

RPC，表示远程过程调用，对于Java这种面试对象语言，也可以理解为远程方法调用，RPC调用和HTTP调用是有区别的，RPC表示的是一种调用远程方法的方式，可以使用HTTP协议、或直接基于TCP协议来实现RPC，在Java中，我们可以通过直接使用某个服务接口的代理对象来执行方法，而底层则通过构造HTTP请求来调用远端的方法，所以，有一种说法是RPC协议是HTTP协议之上的一种协议，也是可以理解的。

>数据一致性模型

数据一致性模型有哪些
- 强一致性：当更新操作完成之后，任何多个后续进程的访问都会返回最新的更新过的值，这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。根据 CAP理论，这种实现需要牺牲可用性。
- 弱一致性：系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。用户读到某一操作对系统数据的更新需要一段时间，我们称这段时间为“不一致性窗口”。
- 最终一致性：最终一致性是弱一致性的特例，强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。到达最终一致性的时间，就是不一致窗口时间，在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。最终一致性模型根据其提供的不同保证可以划分为更多的模型，包括因果一致性和会话一致性等。

>分布式ID是什么？有哪些解决方案？

在开发中，我们通常会需要一个唯一ID来标识数据，如果是单体架构，我们可以通过数据库的主键，或直接在内存中维护一个自增数字来作为ID都是可以的，但对于一个分布式系统，就会有可能会出现ID冲突，此时有以下解决方案：

- uuid，这种方案复杂度最低，但是会影响存储空间和性能
- 利用单机数据库的自增主键，作为分布式ID的生成器，复杂度适中，ID长度较之uuid更短，但是受到单机数据库性能的限制，并发量大的时候，此方案也不是最优方案
- 利用redis、zookeeper的特性来生成id，比如redis的自增命令、zookeeper的顺序节点，这种方案和单机-数据库(mysql)相比，性能有所提高，可以适当选用
- 雪花算法，一切问题如果能直接用算法解决，那就是最合适的，利用雪花算法也可以生成分布式ID，底层原理就是通过某台机器在某一毫秒内对某一个数字自增，这种方案也能保证分布式架构中的系统id唯一，但是只能保证趋势递增。业界存在tinyid、leaf等开源中间件实现了雪花算法。

>分布式锁的使用场景是什么？有哪些实现方案？

在单体架构中，多个线程都是属于同一个进程的，所以在线程并发执行时，遇到资源竞争时，可以利用ReentrantLock、synchronized等技术来作为锁，来控制共享资源的使用。
而在分布式架构中，多个线程是可能处于不同进程中的，而这些线程并发执行遇到资源竞争时，利用ReentrantLock、synchronized等技术是没办法来控制多个进程中的线程的，所以需要分布式锁，意思就是，需要一个分布式锁生成器，分布式系统中的应用程序都可以来使用这个生成器所提供的锁，从而达到多个进程中的线程使用同一把锁。

目前主流的分布式锁的实现方案有两种：

- zookeeper：利用的是zookeeper的临时节点、顺序节点、watch机制来实现的，zookeeper分布式锁的特点是高一致性，因为zookeeper保证的是CP，所以由它实现的分布式锁更可靠，不会出现混乱
- redis：利用redis的setnx、lua脚本、消费订阅等机制来实现的，redis分布式锁的特点是高可用，因为redis保证的是AP，所以由它实现的分布式锁可能不可靠，不稳定（一旦redis中的数据出现了不一致），可能会出现多个客户端同时加到锁的情况

> 什么是分布式事务？有哪些实现方案？

在分布式系统中，一次业务处理可能需要多个应用来实现，比如用户发送一次下单请求，就涉及到订单系统创建订单、库存系统减库存，而对于一次下单，订单创建与减库存应该是要同时成功或同时失败的，但在分布式系统中，如果不做处理，就很有可能出现订单创建成功，但是减库存失败，那么解决这类问题，就需要用到分布式事务。常用解决方案有：
本地消息表：创建订单时，将减库存消息加入在本地事务中，一起提交到数据库存入本地消息表，然后调用库存系统，如果调用成功则修改本地消息状态为成功，如果调用库存系统失败，则由后台定时任务从本地消息表中取出未成功的消息，重试调用库存系统

- 消息队列：目前RocketMQ中支持事务消息，它的工作原理是：

1. 生产者订单系统先发送一条half消息到Broker，half消息对消费者而言是不可见的
2. 再创建订单，根据创建订单成功与否，向Broker发送commit或rollback
3. 并且生产者订单系统还可以提供Broker回调接口，当Broker发现一段时间half消息没有收到任何操作命令，则会主动调此接口来查询订单是否创建成功
4. 一旦half消息commit了，消费者库存系统就会来消费，如果消费成功，则消息销毁，分布式事务成功结束
5. 如果消费失败，则根据重试策略进行重试，最后还失败则进入死信队列，等待进一步处理
   
- Seata：阿里开源的分布式事务框架，支持AT、TCC等多种模式，底层都是基于两阶段提交理论来实现的

## zookeeper
是一个分布式的，开放源码的分布式应用程序协调服务
>什么是ZAB协议

ZAB协议是Zookeeper用来实现一致性的原子广播协议，该协议描述了Zookeeper是如何实现一致性的，分为三个阶段：

- 领导者选举阶段：从Zookeeper集群中选出一个节点作为Leader，所有的写请求都会由Leader节点来处理
- 数据同步阶段：集群中所有节点中的数据要和Leader节点保持一致，如果不一致则要进行同步
- 请求广播阶段：当Leader节点接收到写请求时，会利用两阶段提交来广播该写请求，使得写请求像事务一样在其他节点上执行，达到节点上的数据实时一致

但值得注意的是，Zookeeper只是尽量的在达到强一致性，实际上仍然只是最终一致性的。

>为什么Zookeeper可以用来作为注册中心

可以利用Zookeeper的临时节点和watch机制来实现注册中心的自动注册和发现，另外Zookeeper中的数据都是存在内存中的，并且Zookeeper底层采用了nio，多线程模型，所以Zookeeper的性能也是比较高的，所以可以用来作为注册中心，但是如果考虑到注册中心应该是注册可用性的话，那么Zookeeper则不太合适，因为Zookeeper是CP的，它注重的是一致性，所以集群数据不一致时，集群将不可用，所以用Redis、Eureka、Nacos来作为注册中心将更合适。

> Zookeeper中的领导者选举的流程是怎样的？

对于Zookeeper集群，整个集群需要从集群节点中选出一个节点作为Leader，大体流程如下：
集群中各个节点首先都是观望状态（LOOKING），一开始都会投票给自己，认为自己比较适合作为leader
然后相互交互投票，每个节点会收到其他节点发过来的选票，然后pk，先比较zxid，zxid大者获胜，zxid如果相等则比较myid，myid大者获胜
一个节点收到其他节点发过来的选票，经过PK后，如果PK输了，则改票，此节点就会投给zxid或myid更大的节点，并将选票放入自己的投票箱中，并将新的选票发送给其他节点
如果pk是平局则将接收到的选票放入自己的投票箱中
如果pk赢了，则忽略所接收到的选票
当然一个节点将一张选票放入到自己的投票箱之后，就会从投票箱中统计票数，看是否超过一半的节点都和自己所投的节点是一样的，如果超过半数，那么则认为当前自己所投的节点是leader
集群中每个节点都会经过同样的流程，pk的规则也是一样的，一旦改票就会告诉给其他服务器，所以最终各个节点中的投票箱中的选票也将是一样的，所以各个节点最终选出来的leader也是一样的，这样集群的leader就选举出来了

>Zookeeper集群中节点之间数据是如何同步的

- 首先集群启动时，会先进行领导者选举，确定哪个节点是Leader，哪些节点是Follower和Observer
- 然后Leader会和其他节点进行数据同步，采用发送快照和发送Diff日志的方式
- 集群在工作过程中，所有的写请求都会交给Leader节点来进行处理，从节点只能处理读请求
- Leader节点收到一个写请求时，会通过两阶段机制来处理
- Leader节点会将该写请求对应的日志发送给其他Follower节点，并等待Follower节点持久化日志成功
- Follower节点收到日志后会进行持久化，如果持久化成功则发送一个Ack给Leader节点
- 当Leader节点收到半数以上的Ack后，就会开始提交，先更新Leader节点本地的内存数据
- 然后发送commit命令给Follower节点，Follower节点收到commit命令后就会更新各自本地内存数据
- 同时Leader节点还是将当前写请求直接发送给Observer节点，Observer节点收到Leader发过来的写请求后直接执行更新本地内存数据
- 最后Leader节点返回客户端写请求响应成功
- 通过同步机制和两阶段提交机制来达到集群中节点数据一致

> zookeeper的使用场景
命名服务，配置管理，集群管理

> 简述zk的命名服务、配置管理、集群管理

- 命名服务：
通过指定的名字来获取资源或者服务地址。Zookeeper可以创建一个全局唯一的路径，这个路径就可以作为一个名字。被命名的实体可以是集群中的机器，服务的地址，或者是远程的对象等。一些分布式服务框架（RPC、RMI）中的服务地址列表，通过使用命名服务，客户端应用能够根据特定的名字来获取资源的实体、服务地址和提供者信息等
- 配置管理：
实际项目开发中，经常使用.properties或者xml需要配置很多信息，如数据库连接信息、fps地址端口等等。程序分布式部署时，如果把程序的这些配置信息保存在zk的znode节点下，当你要修改配置，即znode会发生变化时，可以通过改变zk中某个目录节点的内容，利用watcher通知给各个客户端，从而更改配置。
- 集群管理：
集群管理包括集群监控和集群控制，就是监控集群机器状态，剔除机器和加入机器。zookeeper可以方便集群机器的管理，它可以实时监控znode节点的变化，一旦发现有机器挂了，该机器就会与zk断开连接，对应的临时目录节点会被删除，其他所有机器都收到通知。新机器加入也是类似。

>讲下Zookeeper中的watch机制

客户端，可以通过在znode上设置watch，实现实时监听znode的变化

Watch事件是一个一次性的触发器，当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端

- 父节点的创建，修改，删除都会触发Watcher事件。
- 子节点的创建，删除会触发Watcher事件。
  
- 一次性：一旦被触发就会移除，再次使用需要重新注册，因为每次变动都需要通知所有客户端，一次性可以减轻压力，3.6.0默认持久递归，可以触发多次
- 轻量：只通知发生了事件，不会告知事件内容，减轻服务器和带宽压力

Watcher 机制包括三个角色：客户端线程、客户端的 WatchManager 以及 ZooKeeper 服务器
1. 客户端向 ZooKeeper 服务器注册一个 Watcher 监听， 
2. 把这个监听信息存储到客户端的 WatchManager 中 
3. 当 ZooKeeper 中的节点发生变化时，会通知客户端，客户端会调用相应 Watcher 对象中的回调方法。watch回调是串行同步的 

>Zookeeper和Eureka的区别

zk：***CP设计(强一致性)***，目标是一个分布式的协调系统，用于进行资源的统一管理。
 
当节点crash后，需要进行leader的选举，在这个期间内，zk服务是不可用的。

eureka：***AP设计（高可用）***，目标是一个服务注册发现系统，专门用于微服务的服务发现注册。

Eureka各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册时如果发现连接失败，会自动切换至其他节点，只要有一台Eureka还在，就能保证注册服务可用（保证可用性），只不过查到的信息可能不是最新的（不保证强一致性）

同时当eureka的服务端发现85%以上的服务都没有心跳的话，它就会认为自己的网络出了问题，就不会从服务列表中删除这些失去心跳的服务，同时eureka的客户端也会缓存服务信息。eureka对于服务注册发现来说是非常好的选择。
## Dubbo
是阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。
>Dubbo支持哪些负载均衡策略

- 随机：从多个服务提供者随机选择一个来处理本次请求，调用量越大则分布越均匀，并支持按权重设置随机概率
- 轮询：依次选择服务提供者来处理请求， 并支持按权重进行轮询，底层采用的是平滑加权轮询算法
- 最小活跃调用数：统计服务提供者当前正在处理的请求，下次请求过来则交给活跃数最小的服务器来处理
- 一致性哈希：相同参数的请求总是发到同一个服务提供者

>Dubbo是如何完成服务导出的？

1. 首先Dubbo会将程序员所使用的@DubboService注解或@Service注解进行解析得到程序员所定义的服务参数，包括定义的服务名、服务接口、服务超时时间、服务协议等等，得到一个ServiceBean。
2. 然后调用ServiceBean的export方法进行服务导出
3. 然后将服务信息注册到注册中心，如果有多个协议，多个注册中心，那就将服务按单个协议，单个注册中心进行注册
4. 将服务信息注册到注册中心后，还会绑定一些监听器，监听动态配置中心的变更
5. 还会根据服务协议启动对应的Web服务器或网络框架，比如Tomcat、Netty等

>Dubbo是如何完成服务引入的？

1. 当程序员使用`@Reference`注解来引入一个服务时，Dubbo会将注解和服务的信息解析出来，得到当前所引用的服务名、服务接口是什么
2. 然后从注册中心进行查询服务信息，得到服务的提供者信息，并存在消费端的服务目录中
3. 并绑定一些监听器用来监听动态配置中心的变更
4. 然后根据查询得到的服务提供者信息生成一个服务接口的代理对象，并放入Spring容器中作为Bean

>Dubbo的架构设计是怎样的？

一个Rpc框架

Dubbo中的架构设计是非常优秀的，分为了很多层次，并且每层都是可以扩展的，比如：
- Proxy服务代理层，支持JDK动态代理、javassist等代理机制
- Registry注册中心层，支持Zookeeper、Redis等作为注册中心
- Protocol远程调用层，支持Dubbo、Http等调用协议
- Transport网络传输层，支持netty、mina等网络传输框架
- Serialize数据序列化层，支持JSON、Hessian等序列化机制

各层说明

- config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类
- proxy 服务代理层：服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton, 以 ServiceProxy 为中心，扩展接口为 ProxyFactory
- registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService
- cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance
- monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService
- protocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter
- exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer
- transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec
- serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool

>Spring Cloud和Dubbo有哪些区别？

Spring Cloud是一个微服务框架，提供了微服务领域中的很多功能组件，Dubbo一开始是一个RPC调用框架，核心是解决服务调用间的问题，Spring Cloud是一个大而全的框架，Dubbo则更侧重于服务调用，所以Dubbo所提供的功能没有Spring Cloud全面，但是Dubbo的服务调用性能比Spring Cloud高，不过Spring Cloud和Dubbo并不是对立的，是可以结合起来一起使用的。
## 分布式的场景问题
### 负载均衡算法有哪些

1. 轮询法：将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。
2. 随机法：通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多，其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。
3. 源地址哈希法：源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。
4. 加权轮询法：不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。
5. 加权随机法：与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。
6. 最小连接数法：最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。

### 分布式架构下，Session 共享有什么方案
1. 采用无状态服务，抛弃session
2. 存入cookie（有安全风险）
3. 服务器之间进行 Session 同步，这样可以保证每个服务器上都有全部的 Session 信息，不过当服务器数量比较多的时候，同步是会有延迟甚至同步失败；
4.  IP 绑定策略
使用 Nginx （或其他复杂均衡软硬件）中的 IP 绑定策略，同一个 IP 只能在指定的同一个机器访问，但是这样做失去了负载均衡的意义，当挂掉一台服务器的时候，会影响一批用户的使用，风险很大；
5. 使用 Redis 存储
把 Session 放到 Redis 中存储，虽然架构上变得复杂，并且需要多访问一次 Redis ，但是这种方案带来的好处也是很大的：
- 实现了 Session 共享；
- 可以水平扩展（增加 Redis 服务器）；
- 服务器重启 Session 不丢失（不过也要注意 Session 在 Redis 中的刷新/失效机制）；
- 不仅可以跨服务器 Session 共享，甚至可以跨平台（例如网页端和 APP 端）。

### 如何实现接口的幂等性
用在接口上就可以理解为：同一个接口，多次发出同一个请求，必须保证操作只执行一次。 调用接口发生异常并且重复尝试时，总是会造成系统所无法承受的损失，所以必须阻止这种现象的发生。

- 唯一id。每次操作，都根据操作和内容生成唯一的id，在执行之前先判断id是否存在，如果不存在则执行后续操作，并且保存到数据库或者redis等。
服务端提供发送token的接口，业务调用接口前先获取token,然后调用业务接口请求时，把token携带过去,务器判断token是否存在redis中，存在表示第一次请求，可以继续执行业务，执行业务完成后，最后需要把redis中的token删除
- 建去重表。将业务中有唯一标识的字段保存到去重表，如果表中存在，则表示已经处理过了
- 版本控制。增加版本号，当版本号符合时，才能更新数据
- 状态控制。例如订单有状态已支付 未支付 支付中 支付失败，当处于未支付的时候才允许修改为支付中等

### 存储拆分后如何解决唯一主键问题

- UUID：简单、性能好，没有顺序，没有业务含义，存在泄漏mac地址的风险
- 数据库主键：实现简单，单调递增，具有一定的业务可读性，强依赖db、存在性能瓶颈，存在暴露业务 信息的风险
- redis，mongodb，zk等中间件：增加了系统的复杂度和稳定性  
- 雪花算法

### 如何解决不使用分区键的查询问题

- 映射：将查询条件的字段与分区键进行映射，建一张单独的表维护(使用覆盖索引)或者在缓存中维护
- 基因法：分区键的后x个bit位由查询字段进行hash后占用，分区键直接取x个bit位获取分区，查询字段进行hash获取分区，适合非分区键查询字段只有一个的情况
- 冗余：查询字段冗余存储


### 缓存

> 分布式系统中常用的缓存方案有哪些

- 客户端缓存：页面和浏览器缓存，APP缓存，H5缓存，localStorage 和 sessionStorage 
- CDN缓存：内容存储：数据的缓存，内容分发：负载均衡
- nginx缓存：静态资源
- 服务端缓存：本地缓存，外部缓存
- 数据库缓存：持久层缓存（mybatis，hibernate多级缓存），mysql查询缓存 操作系统缓存：PageCache、BufferCache

>缓存过期都有哪些策略？

- 定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立 即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量
- 惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，但是很消耗内存、许多的过期数据都还存在内存中。极端情况可能出现大量的过期key没有 再次被访问，从而不会被清除，占用大量内存。
- 定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key（是随机的）， 并清除其中已过期的key。该策略是定时过期和惰性过期的折中方案。通过调整定时扫描的时间间隔和 每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。
- 分桶策略：定期过期的优化，将过期时间点相近的key放在一起，按时间扫描分桶。

>常见的缓存淘汰算法

- FIFO（First In First Out，先进先出），根据缓存被存储的时间，离当前最远的数据优先被淘汰；
- LRU（LeastRecentlyUsed，最近最少使用），根据最近被使用的时间，离当前最远的数据优先被淘汰；
- LFU（LeastFrequentlyUsed，最不经常使用），在一段时间内，缓存数据被使用次数最少的会被淘汰。

>布隆过滤器原理，优缺点

- 位图：int[10]，每个int类型的整数是4*8=32个bit，则int[10]一共有320 bit，每个bit非0即1，初始化时都是0
添加数据时：将数据进行hash得到hash值，对应到bit位，将该bit改为1，hash函数可以定义多个，则一个数据添加会将多个（hash函数个数）bit改为1，多个hash函数的目的是减少hash碰撞的概率
查询数据：hash函数计算得到hash值，对应到bit中，如果有一个为0，则说明数据不在bit中，如果都为1，则该数据可能在bit中

- 优点：
  - 占用内存小
  - 增加和查询元素的时间复杂度为：O(K), (K为哈希函数的个数，一般比较小)，与数据量大小无关哈希函数相互之间没有关系，方便硬件并行运算
  - 布隆过滤器不需要存储元素本身，在某些对保密要求比较严格的场合有很大优势 数据量很大时，布隆过滤器可以表示全集
  - 使用同一组散列函数的布隆过滤器可以进行交、并、差运算
- 缺点：
  - 误判率，即存在假阳性(False  Position)，不能准确判断元素是否在集合中不能获取元素本身
  - 一般情况下不能从布隆过滤器中删除元素


>分布式缓存寻址算法

- hash算法：根据key进行hash函数运算、结果对分片数取模，确定分片适合固定分片数的场景，扩展分片或者减少分片时，所有数据都需要重新计算分片、存储
- 一致性hash：将整个hash值得区间组织成一个闭合的圆环，计算每台服务器的hash值、映射到圆环中。使用相同的hash算法计算数据的hash值，映射到圆环，顺时针寻找，找到的第一个服务器就是数据存储的服务器。新增及减少节点时只会影响节点到他逆时针最近的一个服务器之间的值 存在hash环倾斜的问题，即服务器分布不均匀，可以通过虚拟节点解决
- hash slot：将数据与服务器隔离开，数据与slot映射，slot与服务器映射，数据进行hash决定存放的slot，新增及删除节点时，将slot进行迁移即可

### 服务
> 什么是服务雪崩？什么是服务限流？

当服务A调用服务B，服务B调用C，此时大量请求突然请求服务A，假如服务A本身能抗住这些请求，但是如果服务C抗不住，导致服务C请求堆积，从而服务B请求堆积，从而服务A不可用，这就是服务雪崩，解决方式就是服务降级和服务熔断。

服务限流是指在高并发请求下，为了保护系统，可以对访问服务的请求进行数量上的限制，从而防止系统不被大量请求压垮，在秒杀中，限流是非常重要的。

>什么是服务熔断？什么是服务降级？区别是什么？

- 服务熔断是指，当服务A调用的某个服务B不可用时，上游服务A为了保证自己不受影响，从而不再调用服务B，直接返回一个结果，减轻服务A和服务B的压力，直到服务B恢复。
- 服务降级是指，当发现系统压力过载时，可以通过关闭某个服务，或限流某个服务来减轻系统压力，这就是服务降级。

相同点：
- 都是为了防止系统崩溃
- 都让用户体验到某些功能暂时不可用
不同点：
熔断是下游服务故障触发的，降级是为了降低系统负载

>SOA、分布式、微服务之间有什么关系和区别？

分布式架构是指将单体架构中的各个部分拆分，然后部署不同的机器或进程中去，SOA和微服务基本上都是分布式架构的

SOA是一种面向服务的架构，系统的所有服务都注册在总线上，当调用服务时，从总线上查找服务信息，然后调用

微服务是一种更彻底的面向服务的架构，将系统中各个功能个体抽成一个个小的应用程序，基本保持一个应用对应的一个服务的架构

>怎么拆分微服务？

- 拆分微服务的时候，为了尽量保证微服务的稳定，会有一些基本的准则：
- 微服务之间尽量不要有业务交叉。
- 微服务之前只能通过接口进行服务调用，而不能绕过接口直接访问对方的数据。
  
高内聚，低耦合。

>怎样设计出高内聚、低耦合的微服务？

高内聚低耦合，是一种从上而下指导微服务设计的方法。实现高内聚低耦合的工具主要有 同步的接口调用 和 异步的事件驱动 两种方式。

>有没有了解过DDD领域驱动设计？

什么是DDD： 在2004年，由Eric Evans提出了， DDD是面对软件复杂之道。Domain-Driven- Design –Tackling Complexity in the Heart of Software 

大泥团： 不利于微服务的拆分。大泥团结构拆分出来的微服务依然是泥团机构，当服务业务逐渐复杂，这个泥团又会膨胀成为大泥团。
DDD只是一种方法论，没有一个稳定的技术框架。DDD要求领域是跟技术无关、跟存储无关、跟通信无关。

>什么是中台？

所谓中台，就是将各个业务线中可以复用的一些功能抽取出来，剥离个性，提取共性，形成一些可复用的组件。  

大体上，中台可以分为三类 业务中台、数据中台和技术中台。

大数据杀熟-数据中台 

中台跟DDD结合：  DDD会通过限界上下文将系统拆分成一个一个的领域， 而这种限界上下文，天生就成了中台之间的逻辑屏障。

DDD在技术与资源调度方面都能够给中台建设提供不错的指导。
DDD分为战略设计和战术设计。 上层的战略设计能够很好的指导中台划分，下层的战术设计能够很好的指导微服务搭建。

>你的项目中是怎么保证微服务敏捷开发的？

- 开发运维一体化。
- 敏捷开发： 目的就是为了提高团队的交付效率，快速迭代，快速试错
- 每个月固定发布新版本，以分支的形式保存到代码仓库中。
- 快速入职。
- 任务面板、
- 站立会议。
- 团队人员灵活流动，同时形成各个专家代表

测试环境- 生产环境 -开发测试环境SIT-集成测试环境-压测环境STR-预投产环境-生产环境PRD
晨会、周会、需求拆分会


链路追踪： 1. 基于日志，形成全局事务，落地到日志文件。filebat-logstash-Elasticsearch形成大型报表
2. 基于MQ 需要架构支持，经过流式计算形成可视化的结果
3. 持续集成， SpringBoot marven ，pom-》build-》shell；jenkins
4. AB发布， 蓝绿发布（本地），红黑发布（云计算方式）。老版本和新版本是同时存在的，灰度发布，金丝雀发布


## 消息队列

>如何进行消息队列选型？

- Kafka：
  - 优点： 吞吐量非常大，性能非常好，集群高可用。
  - 缺点：会丢数据，功能比较单一。
  - 使用场景：日志分析、大数据采集
- RabbitMQ：
  - 优点： 消息可靠性高，功能全面。
  - 缺点：吞吐量比较低，消息积累会严重影响性能。erlang语言不好定制。
  - 使用场景：小规模场景。
- RocketMQ：
  - 优点：高吞吐、高性能、高可用，功能非常全面。
  - 缺点：开源版功能不如云上商业版。官方文档和周边生态还不够成熟。客户端只支持java。
  - 使用场景：几乎是全场景。

### RocketMQ

>RocketMQ的事务消息是如何实现的

1. 生产者订单系统先发送一条half消息到Broker，half消息对消费者而言是不可见的
2. 再创建订单，根据创建订单成功与否，向Broker发送commit或rollback
3. 并且生产者订单系统还可以提供Broker回调接口，当Broker发现一段时间half消息没有收到任何操作命令，则会主动调此接口来查询订单是否创建成功
4. 一旦half消息commit了，消费者库存系统就会来消费，如果消费成功，则消息销毁，分布式事务成功结束
5. 如果消费失败，则根据重试策略进行重试，最后还失败则进入死信队列，等待进一步处理

>为什么RocketMQ不使用Zookeeper作为注册中心呢？

根据CAP理论，同时最多只能满足两个点，而zookeeper满足的是CP，也就是说zookeeper并不能保证服务的可用性，zookeeper在进行选举的时候，整个选举的时间太长，期间整个集群都处于不可用的状态，而这对于一个注册中心来说肯定是不能接受的，作为服务发现来说就应该是为可用性而设计。

基于性能的考虑，NameServer本身的实现非常轻量，而且可以通过增加机器的方式水平扩展，增加集群的抗压能力，而zookeeper的写是不可扩展的，而zookeeper要解决这个问题只能通过划分领域，划分多个zookeeper集群来解决，首先操作起来太复杂，其次这样还是又违反了CAP中的A的设计，导致服务之间是不连通的。

持久化的机制来带的问题，ZooKeeper 的 ZAB 协议对每一个写请求，会在每个 ZooKeeper 节点上保持写一个事务日志，同时再加上定期的将内存数据镜像（Snapshot）到磁盘来保证数据的一致性和持久性，而对于一个简单的服务发现的场景来说，这其实没有太大的必要，这个实现方案太重了。而且本身存储的数据应该是高度定制化的。

消息发送应该弱依赖注册中心，而RocketMQ的设计理念也正是基于此，生产者在第一次发送消息的时候从NameServer获取到Broker地址后缓存到本地，如果NameServer整个集群不可用，短时间内对于生产者和消费者并不会产生太大影响。

> RocketMQ的实现原理

RocketMQ由NameServer注册中心集群、Producer生产者集群、Consumer消费者集群和若干Broker（RocketMQ进程）组成，它的架构原理是这样的：
1. Broker在启动的时候去向所有的NameServer注册，并保持长连接，每30s发送一次心跳
2. Producer在发送消息的时候从NameServer获取Broker服务器地址，根据负载均衡算法选择一台服务器来发送消息
3. Consumer消费消息的时候同样从NameServer获取Broker地址，然后主动拉取消息来消费

>RocketMQ为什么速度快

因为使用了顺序存储、Page Cache和异步刷盘。我们在写入commitlog的时候是顺序写入的，这样比随机写入的性能就会提高很多，写入commitlog的时候并不是直接写入磁盘，而是先写入操作系统的PageCache，最后由操作系统异步将缓存中的数据刷到磁盘

>消息队列如何保证消息可靠传输

消息可靠传输代表了两层意思，既不能多也不能少。为了保证消息不多，也就是消息不能重复，也就是生产者不能重复生产消息，或者消费者不能重复消费消息

首先要确保消息不多发，这个不常出现，也比较难控制，因为如果出现了多发，很大的原因是生产者自己的原因，如果要避免出现问题，就需要在消费端做控制

要避免不重复消费，最保险的机制就是消费者实现幂等性，保证就算重复消费，也不会有问题，通过幂等性，也能解决生产者重复发送消息的问题
消息不能少，意思就是消息不能丢失，生产者发送的消息，消费者一定要能消费到，对于这个问题，就要考虑两个方面

生产者发送消息时，要确认broker确实收到并持久化了这条消息，比如RabbitMQ的confirm机制，Kafka的ack机制都可以保证生产者能正确的将消息发送给broker
broker要等待消费者真正确认消费到了消息时才删除掉消息，这里通常就是消费端ack机制，消费者接收到一条消息后，如果确认没问题了，就可以给broker发送一个ack，broker接收到ack后才会删除消息

> 消息队列有哪些作用

- 解耦：使用消息队列来作为两个系统之间的通讯方式，两个系统不需要相互依赖了
- 异步：系统A给消息队列发送完消息之后，就可以继续做其他事情了
- 流量削峰：如果使用消息队列的方式来调用某个系统，那么消息将在队列中排队，由消费者自己控制消费速度

>死信队列是什么？延时队列是什么？

死信队列也是一个消息队列，它是用来存放那些没有成功消费的消息的，通常可以用来作为消息重试
延时队列就是用来存放需要在指定时间被处理的元素的队列，通常可以用来处理一些具有过期性操作的业务，比如十分钟内未支付则取消订单

>如何保证消息的高效读写？

零拷贝： kafka和RocketMQ都是通过零拷贝技术来优化文件读写。
传统文件复制方式： 需要对文件在内存中进行四次拷贝。

零拷贝少复制两次

零拷贝： 有两种方式， mmap和transfile，Java当中对零拷贝进行了封装， Mmap方式通过`MappedByteBuffer`对象进行操作，而transfile通过`FileChannel`来进行操作。Mmap 适合比较小的文件，通常文件大小不要超过1.5G ~2G 之间。Transfile没有文件大小限制。

RocketMQ当中使用Mmap方式来对他的文件进行读写。

在kafka当中，他的index日志文件也是通过mmap的方式来读写的。在其他日志文件当中，并没有使用零拷贝的方式。Kafka使用transfile方式将硬盘数据加载到网卡。


# 网络

### tcp 三次握手
> TCP三次握手过程

TCP(Transmission Control Protocol)　传输控制协议

tcp的6种标志位的分别代表：
- `SYN`(synchronous建立联机)
- `ACK`(acknowledgement 确认)
- `PSH`(push传送)
- `FIN`(finish结束)
- `RST`(reset重置)
- `URG`(urgent紧急)
- `Sequence number`(顺序号码)
- `Acknowledge number`(确认号码)

客户端TCP状态迁移：
- `CLOSED`->`SYN_SENT`->`ESTABLISHED`->`FIN_WAIT_1`->`FIN_WAIT_2`->`TIME_WAIT`->`CLOSED`

服务器TCP状态迁移：
- `CLOSED`->`LISTEN`->`SYN`收到->`ESTABLISHED`->`CLOSE_WAIT`->`LAST_AC`K->`CLOSED`

- `LISTEN` - 侦听来自远方TCP端口的连接请求；
- `SYN-SENT` -在发送连接请求后等待匹配的连接请求；
- `SYN-RECEIVED` - 在收到和发送一个连接请求后等待对连接请求的确认；
- `ESTABLISHED`- 代表一个打开的连接，数据可以传送给用户；
- `FIN-WAIT-1` - 等待远程TCP的连接中断请求，或先前的连接中断请求的确认；
- `FIN-WAIT-2` - 从远程TCP等待连接中断请求；
- `CLOSE-WAIT` - 等待从本地用户发来的连接中断请求；
- `CLOSING` -等待远程TCP对连接中断的确认；
- `LAST-ACK` - 等待原来发向远程TCP的连接中断请求的确认；
- `TIME-WAIT` -等待足够的时间以确保远程TCP接收到连接中断请求的确认；
- `CLOSED` - 没有任何连接状态；

（1）第一次握手：建立连接时，客户端A发送SYN包（SYN=j）到服务器B，并进入SYN_SEND状态，等待服务器B确认。

（2）第二次握手：服务器B收到SYN包，必须确认客户A的SYN（ACK=j+1），同时自己也发送一个SYN包（SYN=k），即SYN+ACK包，此时服务器B进入`SYN_RECV`状态。

（3）第三次握手：客户端A收到服务器B的SYN＋ACK包，向服务器B发送确认包ACK（ACK=k+1），此包发送完毕，客户端A和服务器B进入`ESTABLISHED`状态，完成三次握手。

完成**三次握手**，客户端与服务器开始传送数据。

确认号：其数值等于发送方的发送序号 +1(即接收方期望接收的下一个序列号)。


>TCP发数据过程中必须按顺序接收吗

有序号，是没必要按顺序接受的

>四次挥手，关闭连接

由于TCP连接是***全双工***的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。

CP的连接的拆除需要发送四个包，因此称为四次挥手(four-way handshake)。客户端或服务器均可主动发起挥手动作，在socket编程中，任何一方执行close()操作即可产生挥手操作。

（1）客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送。

（2）服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1。和SYN一样，一个FIN将占用一个序号。

（3）服务器B关闭与客户端A的连接，发送一个FIN给客户端A。

（4）客户端A发回ACK报文确认，并将确认序号设置为收到序号加1。

一个TCP连接存在双向的读写通道。

简单说来是 “先关读，后关写”，一共需要四个阶段。以客户机发起关闭连接为例：
- 1.服务器读通道关闭
- 2.客户机写通道关闭
- 3.客户机读通道关闭
- 4.服务器写通道关闭

> 三次握手的目的

为了防止A端已经失效的连接请求再次发送到B端，如果这时B端又再次向A端发出确认连接请求造成错误。

为了避免重复连接。

> 浏览器发出一个请求到收到响应经历了哪些步骤？

1. 浏览器解析用户输入的URL，生成一个HTTP格式的请求
2. 先根据URL域名从本地hosts文件查找是否有映射IP，如果没有就将域名发送给电脑所配置的DNS进行域名解析，得到IP地址
3. 浏览器通过操作系统将请求通过四层网络协议发送出去
4. 途中可能会经过各种路由器、交换机，最终到达服务器
5. 服务器收到请求后，根据请求所指定的端口，将请求传递给绑定了该端口的应用程序，比如8080被tomcat占用了
6. tomcat接收到请求数据后，按照http协议的格式进行解析，解析得到所要访问的servlet
7. 然后servlet来处理这个请求，如果是SpringMVC中的DispatcherServlet，那么则会找到对应的Controller中的方法，并执行该方法得到结果
8. Tomcat得到响应结果后封装成HTTP响应的格式，并再次通过网络发送给浏览器所在的服务器
9. 浏览器所在的服务器拿到结果后再传递给浏览器，浏览器则负责解析并渲染

>跨域请求是什么？有什么问题？怎么解决？

跨域是指浏览器在发起网络请求时，会检查该请求所对应的协议、域名、端口和当前网页是否一致，如果不一致则浏览器会进行限制，比如在www.baidu.com的某个网页中，如果使用ajax去访问www.jd.com是不行的，但是如果是img、iframe、script等标签的src属性去访问则是可以的，之所以浏览器要做这层限制，是为了用户信息安全。但是如果开发者想要绕过这层限制也是可以的：

response添加header，比如resp.setHeader("Access-Control-Allow-Origin", "*");表示可以访问所有网站，不受是否同源的限制
jsonp的方式，该技术底层就是基于script标签来实现的，因为script标签是可以跨域的
后台自己控制，先访问同域名下的接口，然后在接口中再去使用HTTPClient等工具去调用目标接口
网关，和第三种方式类似，都是交给后台服务来进行跨域访问
# 操作系统
## Volatile如何保证线程可见性之总线锁、缓存一致性协议

>Volatile如何保证线程可见性之总线锁、缓存一致性协议

### 缓存一致性协议
>多线程多cpu导致的数据不同步，存在缓存不一致性

操作系统提供了**总线锁定**的机制。前端总线(也叫CPU总线，Front Side Bus）)是所有CPU与芯片组连接的主干道，负责CPU与外界所有部件的通信，包括高速缓存、内存、北桥，其控制总线向各个部件发送控制信号、通过地址总线发送地址信号指定其要访问的部件、通过数据总线双向传输。在CPU1要做 i++操作的时候，其在总线上发出一个`LOCK`#信号，其他处理器就不能操作缓存了该共享变量内存地址的缓存，也就是阻塞了其他CPU，使该处理器可以独享此共享内存。

但我们只需要对此共享变量的操作是原子就可以了，而总线锁定把CPU和内存的通信给锁住了，使得在锁定期间，其他处理器不能操作其他内存地址的数据，从而开销较大，所以后来的CPU都提供了缓存一致性机制，Intel的奔腾486之后就提供了这种优化。

缓存一致性：缓存一致性机制就整体来说，是当某块CPU对缓存中的数据进行操作了之后，就通知其他CPU放弃储存在它们内部的缓存，或者从主内存中重新读取, 用MESI阐述原理如下：

`MESI`协议：是以缓存行(缓存的基本数据单位，在Intel的CPU上一般是64字节)的几个状态来命名的(全名是`Modified`、`Exclusive`、 `Share or Invalid`)。该协议要求在每个缓存行上维护两个状态位，使得每个数据单位可能处于M、E、S和I这四种状态之一，各种状态含义如下：

-​ M：被修改的。处于这一状态的数据，只在本CPU中有缓存数据，而其他CPU中没有。同时其状态相对于内存中的值来说，是已经被修改的，且没有更新到内存中。
- ​E：于这一状态的数据，只有在本CPU中有缓存，且其数据没有修改，即与内存中一致。
- ​S：共享的独占的。处于这一状态的数据在多个CPU中都有缓存，且与内存一致。
​- I：无效的。本CPU中的这份缓存已经无效。

一个处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主存地址的操作，如果监听到，则必须在此操作执行前把其缓存行中的数据写回内存。

一个处于S状态的缓存行，必须时刻监听使该缓存行无效或者独享该缓存行的请求，如果监听到，则必须把其缓存行状态设置为I。

一个处于E状态的缓存行，必须时刻监听其他试图读取该缓存行对应的主存地址的操作，如果监听到，则必须把其缓存行状态设置为S。

​ 当CPU需要读取数据时，如果其缓存行的状态是I的，则需要从内存中读取，并把自己状态变成S，如果不是I，则可以直接读取缓存中的值，但在此之前，必须要等待其他CPU的监听结果，如其他CPU也有该数据的缓存且状态是M，则需要等待其把缓存更新到内存之后，再读取。

​ 当CPU需要写数据时，只有在其缓存行是M或者E的时候才能执行，否则需要发出特殊的RFO指令(Read Or Ownership，这是一种总线事务)，通知其他CPU置缓存无效(I)，这种情况下性能开销是相对较大的。在写入完成后，修改其缓存状态为M。

所以如果一个变量在某段时间只被一个线程频繁地修改，则使用其内部缓存就完全可以办到，不涉及到总线事务，如果缓存一会被这个CPU独占、一会被那个CPU 独占，这时才会不断产生RFO指令影响到并发性能。这里说的缓存频繁被独占并不是指线程越多越容易触发，而是这里的CPU协调机制，这有点类似于有时多线程并不一定提高效率，原因是线程挂起、调度的开销比执行任务的开销还要大，这里的多CPU也是一样，如果在CPU间调度不合理，也会形成RFO指令的开销比任务开销还要大。当然，这不是编程者需要考虑的事，操作系统会有相应的内存地址的相关判断
#### MESI失效的情景
>MESI失效的情景

并非所有情况都会使用缓存一致性，如被操作的数据不能被缓存在CPU内部或操作数据跨越多个缓存行(状态无法标识)，则处理器会调用总线锁定;另外当CPU不支持缓存锁定时，自然也只能用总线锁定了，比如说奔腾486以及更老的CPU。总线事务的竞争，虽然有很高的一致性但是效率非常低。

缓存一致性协议有多种，但是日常处理的大多数计算机设备都属于”嗅探（snooping）”机制，它的基本思想是：
所有内存的传输都发生在一条共享的总线上，而所有的处理器都能看到这条总线：缓存本身是独立的，但是内存是共享资源，所有的内存访问都要经过仲裁（同一个指令周期中，只有一个CPU缓存可以读写内存）。
CPU缓存不仅仅在做内存传输的时候才与总线打交道，而是不停在嗅探总线上发生的数据交换，跟踪其他缓存在做什么。所以当一个缓存代表它所属的处理器去读写内存时，其它处理器都会得到通知，它们以此来使自己的缓存保持同步。只要某个处理器一写内存，其它处理器马上知道这块内存在它们的缓存段中已失效。

#### MESI协议的问题
>既然CPU有了MESI协议可以保证cache的一致性，那么为什么还需要volatile这个关键词来保证可见性(内存屏障)？或者是只有加了volatile的变量在多核cpu执行的时候才会触发缓存一致性协议？

两个解释结论：
<!-- 因为volatile关键字保证可见性. -->

多核情况下，所有的cpu操作都会涉及缓存一致性的校验，只不过该协议是弱一致性，不能保证一个线程修改变量后，其他线程立马可见，也就是说虽然其他CPU状态已经置为无效，但是当前CPU可能将数据修改之后又去做其他事情，没有来得及将修改后的变量刷新回主存，而如果此时其他CPU需要使用该变量，则又会从主存中读取到旧的值。而volatile则可以保证可见性，即立即刷新回主存，修改操作和写回操作必须是一个原子操作；
正常情况下，系统操作并不会进行缓存一致性的校验，只有变量被volatile修饰了，该变量所在的缓存行才被赋予缓存一致性的校验功能。
## 锁
### AQS
>AQS

aqs有一个int的state信号量和一个线程组成的双向链表队列组成。

再可重入锁的 的场景下state表示加锁的次数
### ReentrantLock和Synchronized区别，公平锁和非公平锁区别

> `ReentrantLock`和`Synchronized`区别，公平锁和非公平锁区别

- (1) `synchronized` 是Java的一个内置关键字，而`ReentrantLock`是Java的一个类。
- (2) `synchronized`只能是非公平锁。而`ReentrantLock`可以实现公平锁和非公平锁两种。
- (3) `synchronized`不能中断一个等待锁的线程，而`Lock`可以中断一个试图获取锁的线程。
- (4) `synchronized`不能设置超时，而`Lock`可以设置超时。
- (5) `synchronized`会自动释放锁，而`ReentrantLock`不会自动释放锁，必须手动释放，否则可能会导致死锁。
- Synchronized锁的是对象，锁信息保存在对象头中，ReentrantLock int类型的state标识来标识锁的状态

```java
/**
	 * 公平锁实现 ReentrantLock构造方法中设置为true:代表公平锁
	 * 
	 * 设置为false:代表非公平锁 默认也是非公平锁
	 * 
	 */
	/** private ReentrantLock lock = new ReentrantLock(true); */
 
	/** private ReentrantLock lock = new ReentrantLock(false);
```
>Synchronized的锁升级
- 偏向锁：在锁对象的对象头中记录一下当前获取到该锁的线程ID，该线程下次如果又来获取该锁就可以直接获取到了，也就是支持

- 轻量级锁：由偏向锁升级而来，当一个线程获取到锁后，此时这把锁是偏向1锁，此时如果有第二个线程来竞争锁，锁，偏向锁就会升级为轻量级锁，之所以叫轻量级锁，是为了和重量级锁区分开来，轻量级锁底层是通过自旋来实现的，并不会阻塞线程

- 自旋多次仍然没有获取到锁，则会升级为重量锁
- 

>ReentrantLock怎么实现公平锁和非公平锁
公平锁线程会先判断队列有没有线程在排队，有就去排队
非公平锁先去竞争锁，失败了采才去排队

>公平锁和非公平锁的两个区别
只体现在加锁的阶段，

- (1) 线程在获取锁调用lock()时，非公平锁首先会进行一次CAS尝试抢锁，如果此时没有线程持有锁或者正好此刻有线程执行完释放了锁（`state` == 0），那么如果CAS成功则直接占用锁返回。
- (2) 如果非公平锁在上一步获取锁失败了，那么就会进入`nonfairTryAcquire(int acquires)`，在该方法里，如果state的值为0，表示当前没有线程占用锁或者刚好有线程释放了锁，那么就会CAS抢锁，如果抢成功了，就直接返回了，不管是不是有其他线程早就到了在阻塞队列中等待锁了。而公平锁在这里抢到锁了，会判断阻塞队列是不是空的，毕竟要公平就要讲先来后到，如果发现阻塞队列不为空，表示队列中早有其他线程在等待了，那么公平锁情况下线程会乖乖排到阻塞队列的末尾。
  如果非公平锁 (1)(2) 都失败了，那么剩下的过程就和非公平锁一样了。
- (3) 从(1)(2) 可以看出，非公平锁可能导致线程饥饿，但是非公平锁的效率要高




> 常见的锁策略

1、乐观锁和悲观锁

乐观锁和悲观锁是设计上解决线程安全一种思想

悲观锁: 悲观的认为总是有其他线程并发修改，每次都是加锁操作

悲观锁的问题：总是需要竞争锁，进而导致发生线程切换，挂起其他线程；所以性能不高。

乐观锁: 设计上总是乐观的认为数据修改大部分场景都是没有线程并发修改，只有少量情况下才存在。线程安全上采取版本号来控制——用户自己判断版本号，并处理。（版本号后面讲）

乐观锁的问题： 并不总是能处理所有问题，所以会引入一定的系统复杂度。

2、读写锁（`readers-writer lock`）

问题产生： 多线程之间，数据的读取方之间不会产生线程安全问题，但数据的写入方互相之间以及和读者之间都需要进行互斥。如果两种场景下都用同一个锁，就会产生极大的性能损耗。所以读写锁因此而产生。

读写锁（`readers-writer lock`）： 看英文可以顾名思义，在执行加锁操作时需要额外表明读写意图，读者之间并不互斥，而写者则要求与任何人互斥。

3、重量级锁和轻量级锁

我们都知道，在计算机中，应用程序使用计算机的资源都是通过程序调用操作系统再到硬件这一步一步来的 

重量级锁：
操作系统中提供的`mutex `（互斥锁）就是一个重量级锁，这种锁同步方式的成本非常高，主要包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。

缺点： 成本高，很容易引起线程大量调度。

轻量级锁：
重量级锁是相当于重量级锁而言的，将重量级锁在操作系统的内核态操作转为大量的用户态操作。
优点： 减少了无实际竞争情况下，使用重量级锁产生的性能消耗

4、自旋锁（Spin Lock）

没有自旋锁的情况下，抢锁失败，就赶紧放弃CPU，到阻塞队列中等待重新被唤醒，重新抢CPU，重新抢锁。

但是CPU来之不易，放弃CPU就可能需要过很久才能再次被调度。
随着多核 CPU的出现，情况发生变化了;这个锁的线程，很可能正在其他核上运行着,一个锁的持有时间一般都比较短,虽然现在没抢到锁，但很可能在几个时钟周期之后，就能马上抢到锁了。因此，线程就可以不用放弃cpu,多等待一会，就有可能抢到锁。出于这个考虑，就产生了自旋锁。

我们可以将自旋锁简单的理解为以下代码：

自旋锁的缺点： 如果之前的假设（锁很快会被释放）没有满足，则线程其实是光在消耗 CPU 资源，长期在做无用功的。

5、可重入锁和不可重入锁

可重入锁的字面意思是“可以重新进入的锁”，即允许同一个线程多次获取同一把锁。 比如一个递归函数里有加锁操作，递归过程中这个锁会阻塞自己吗？如果不会，那么这个锁就是可重入锁（因为这个原因可重入锁也叫做递归锁）。

Java里只要以`Reentrant`开头命名的锁都是可重入锁，而且JDK提供的所有现成的Lock实现类，包括synchronized关键字锁都是可重入的。

可重入锁的实现是有成本的：

空间上:需要记录锁的持有者
时间上:判断，并记录次数（请求释放数量需要对应上）
管理是有成本的，可重入锁看起来很理想，但需要考虑是否有必要引入该成本。

不可重入锁相对于可重入锁而言，不能重新获取的锁为不可重入锁，也就是不允许同一个线程多次获得同一把锁。

> cas 机制

CAS机制
1、CAS
CAS: 全称Compare and swap，字面意思:“比较并交换

为了提升synchronized保证原子性的效率问题，我们引出了CAS机制

CAS是CPU(硬件） 在电路上来提供提供保证原子性的操作，进而提供给OS（操作系统）、JVM，操作系统和JVM也就可以提供CAS来保证原子性。

jdk5增加的原子性并发包( `java.util.concurrent.*`)，里边的所有并发类都是基于CAS实现的,是一种乐观锁。 JDK 5之前Java语言是靠synchronized关键字保证同步的，这是一种独占锁，也是是悲观锁.

当多个线程同时对某个资源进行CAS操作，只能有一个线程操作成功，但是并不会阻塞其他线程,其他线程只会收到操作失败的信号。可见 CAS 是基于乐观锁实现的

>死锁

多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。 由于线程被无限期地阻塞，因此程序不可能正常终止，就会造成死锁。

即：至少有两个线程，互相持有对方申请的对象锁，造成互相等待。导致没法继续执行
死锁产生的四个必要条件：

- 互斥使用： 即当资源被一个线程使用(占有)时，别的线程不能使用
- 不可抢占： 资源请求者不能强制从资源占有者手中夺取资源，资源只能由资源占有者主动释放。
- 请求和保持： 即当资源请求者在请求其他的资源的同时保持对原有资源的占有。
- 循环等待： 即存在一个等待队列：P1占有P2的资源，P2占有P3的资源，P3占有P1的资源。这样就形成了一个等待环路。

当上述四个条件都成立的时候，便形成死锁。当然，死锁的情况下如果打破上述任何一个条件，便可让死锁消失。

检测死锁的手段:

使用jdk的监控工具，比如`jconsole`、`jstack`查看线程状态

解决方案:

①资源—次性分配（破坏请求与保持条件)
②可剥夺资源:在线程满足条件时，释放掉已占有的资源
③资源有序分配:系统为每类资源赋予一个编号，每个线程按照编号递请求资源，释放则相反
超时释放锁
等待图主动检测死锁 wait-for-graph，保存锁的信息链表，事务等待链表。
# linux

>epoll和poll的区别

- select模型，使用的是数组来存储Socket连接文件描述符，容量是固定的，需要通过轮询来判断是否发生了IO事件
- poll模型，使用的是链表来存储Socket连接文件描述符，容量是不固定的，同样需要通过轮询来判断是否发生了IO事件
- epoll模型，epoll和poll是完全不同的，epoll是一种事件通知模型，当发生了IO事件时，应用程序才进行IO操作，不需要像poll模型那样主动去轮询
# 算法


# 其他知识


框架-》模板-》背景

测试用例，自己写测试考虑测试用例，考虑代码质量，覆盖率   通过测试用例提升自己的代码质量

代码上线，部署到分布式服务器或者云上服务器 需要有一个前端展示界面

做压力测试，比如能够承载多少访问量


难点 
注入fgc的bug

并发的问题